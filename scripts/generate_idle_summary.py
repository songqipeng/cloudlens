#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿæˆæ‰€æœ‰ç§Ÿæˆ·é—²ç½®èµ„æºè¯¦ç»†æ±‡æ€»æŠ¥å‘Š
"""

import json
import os
import sqlite3
from datetime import datetime
from collections import defaultdict
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment


def load_config():
    """åŠ è½½é…ç½®"""
    try:
        with open("config.json", "r") as f:
            return json.load(f)
    except:
        return {"tenants": {"ydzn": {}, "zmyc": {}, "cf": {}}}


def get_ecs_idle_stats(tenant_name="all"):
    """èŽ·å–ECSé—²ç½®ç»Ÿè®¡"""
    db_file = "ecs_monitoring_data_fixed.db"
    if not os.path.exists(db_file):
        return []
    
    try:
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        # èŽ·å–æœ€è¿‘çš„ç›‘æŽ§æ•°æ®,æŒ‰å®žä¾‹åˆ†ç»„è®¡ç®—å¹³å‡CPUä½¿ç”¨çŽ‡
        query = """
        SELECT 
            i.instance_id,
            i.instance_name,
            i.tenant_name,
            i.instance_type,
            i.region_id,
            i.status,
            AVG(m.cpu_percent) as avg_cpu,
            AVG(m.memory_percent) as avg_memory,
            i.creation_time
        FROM instances i
        LEFT JOIN monitoring_data m ON i.instance_id = m.instance_id
        WHERE m.timestamp >= datetime('now', '-7 days')
        """
        
        if tenant_name != "all":
            query += f" AND i.tenant_name = '{tenant_name}'"
        
        query += " GROUP BY i.instance_id HAVING avg_cpu < 10 OR avg_memory < 10"
        
        cursor.execute(query)
        results = cursor.fetchall()
        conn.close()
        
        idle_instances = []
        for row in results:
            idle_instances.append({
                "instance_id": row[0],
                "instance_name": row[1] or "æœªå‘½å",
                "tenant": row[2],
                "instance_type": row[3],
                "region": row[4],
                "status": row[5],
                "avg_cpu": round(row[6], 2) if row[6] else 0,
                "avg_memory": round(row[7], 2) if row[7] else 0,
                "creation_time": row[8]
            })
        
        return idle_instances
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢ECSæ•°æ®å‡ºé”™: {e}")
        return []


def get_rds_idle_stats(tenant_name="all"):
    """èŽ·å–RDSé—²ç½®ç»Ÿè®¡"""
    db_file = "rds_monitoring_data.db"
    if not os.path.exists(db_file):
        return []
    
    try:
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        query = """
        SELECT 
            i.instance_id,
            i.instance_name,
            i.tenant_name,
            i.engine,
            i.engine_version,
            i.region_id,
            i.status,
            AVG(m.cpu_usage) as avg_cpu,
            AVG(m.memory_usage) as avg_memory,
            AVG(m.connections) as avg_connections
        FROM rds_instances i
        LEFT JOIN rds_monitoring_data m ON i.instance_id = m.instance_id
        WHERE m.timestamp >= datetime('now', '-7 days')
        """
        
        if tenant_name != "all":
            query += f" AND i.tenant_name = '{tenant_name}'"
        
        query += " GROUP BY i.instance_id HAVING avg_cpu < 10 OR avg_connections < 5"
        
        cursor.execute(query)
        results = cursor.fetchall()
        conn.close()
        
        idle_instances = []
        for row in results:
            idle_instances.append({
                "instance_id": row[0],
                "instance_name": row[1] or "æœªå‘½å",
                "tenant": row[2],
                "engine": f"{row[3]} {row[4]}",
                "region": row[5],
                "status": row[6],
                "avg_cpu": round(row[7], 2) if row[7] else 0,
                "avg_memory": round(row[8], 2) if row[8] else 0,
                "avg_connections": round(row[9], 2) if row[9] else 0
            })
        
        return idle_instances
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢RDSæ•°æ®å‡ºé”™: {e}")
        return []


def get_slb_idle_stats(tenant_name="all"):
    """èŽ·å–SLBé—²ç½®ç»Ÿè®¡"""
    db_file = "slb_monitoring_data.db"
    if not os.path.exists(db_file):
        return []
    
    try:
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        query = """
        SELECT 
            i.load_balancer_id,
            i.load_balancer_name,
            i.tenant_name,
            i.address_type,
            i.load_balancer_status,
            i.region_id,
            AVG(m.active_connections) as avg_connections,
            AVG(m.new_connections) as avg_new_connections
        FROM slb_instances i
        LEFT JOIN slb_monitoring_data m ON i.load_balancer_id = m.load_balancer_id
        WHERE m.timestamp >= datetime('now', '-7 days')
        """
        
        if tenant_name != "all":
            query += f" AND i.tenant_name = '{tenant_name}'"
        
        query += " GROUP BY i.load_balancer_id HAVING avg_connections < 10"
        
        cursor.execute(query)
        results = cursor.fetchall()
        conn.close()
        
        idle_instances = []
        for row in results:
            idle_instances.append({
                "lb_id": row[0],
                "lb_name": row[1] or "æœªå‘½å",
                "tenant": row[2],
                "address_type": row[3],
                "status": row[4],
                "region": row[5],
                "avg_connections": round(row[6], 2) if row[6] else 0,
                "avg_new_connections": round(row[7], 2) if row[7] else 0
            })
        
        return idle_instances
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢SLBæ•°æ®å‡ºé”™: {e}")
        return []


def get_dns_unused_records():
    """èŽ·å–DNSæœªä½¿ç”¨è®°å½•"""
    db_file = "dns_monitoring_data.db"
    if not os.path.exists(db_file):
        return []
    
    try:
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾å¯èƒ½æœªä½¿ç”¨çš„DNSè®°å½• (è¿™é‡Œç®€å•ç¤ºä¾‹)
        query = """
        SELECT 
            domain_name,
            tenant_name,
            COUNT(*) as record_count
        FROM dns_records
        GROUP BY domain_name, tenant_name
        """
        
        cursor.execute(query)
        results = cursor.fetchall()
        conn.close()
        
        dns_data = []
        for row in results:
            dns_data.append({
                "domain": row[0],
                "tenant": row[1],
                "record_count": row[2]
            })
        
        return dns_data
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢DNSæ•°æ®å‡ºé”™: {e}")
        return []


def generate_summary_report():
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    print("="*80)
    print("ðŸ“Š æ‰€æœ‰ç§Ÿæˆ·é—²ç½®èµ„æºè¯¦ç»†æ±‡æ€»")
    print(f"ðŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    
    config = load_config()
    tenants = list(config.get("tenants", {}).keys())
    
    # æŒ‰ç§Ÿæˆ·ç»Ÿè®¡
    tenant_stats = defaultdict(lambda: {
        "ecs_idle": 0,
        "rds_idle": 0,
        "slb_idle": 0
    })
    
    # 1. ECSé—²ç½®å®žä¾‹
    print("\nðŸ–¥ï¸  ECSé—²ç½®å®žä¾‹ (è¿‡åŽ»7å¤©å¹³å‡CPU<10% æˆ– å†…å­˜<10%):")
    print("-"*80)
    ecs_idle = get_ecs_idle_stats()
    if ecs_idle:
        for instance in ecs_idle:
            tenant_stats[instance["tenant"]]["ecs_idle"] += 1
            print(f"ç§Ÿæˆ·: {instance['tenant']:8s} | "
                  f"å®žä¾‹: {instance['instance_name'][:30]:30s} | "
                  f"ç±»åž‹: {instance['instance_type']:15s} | "
                  f"CPU: {instance['avg_cpu']:5.2f}% | "
                  f"å†…å­˜: {instance['avg_memory']:5.2f}% | "
                  f"åœ°åŸŸ: {instance['region']}")
        print(f"\næ€»è®¡: {len(ecs_idle)} å°é—²ç½®ECSå®žä¾‹")
    else:
        print("æœªå‘çŽ°é—²ç½®ECSå®žä¾‹")
    
    # 2. RDSé—²ç½®å®žä¾‹
    print("\n" + "="*80)
    print("ðŸ—„ï¸  RDSé—²ç½®å®žä¾‹ (è¿‡åŽ»7å¤©å¹³å‡CPU<10% æˆ– è¿žæŽ¥æ•°<5):")
    print("-"*80)
    rds_idle = get_rds_idle_stats()
    if rds_idle:
        for instance in rds_idle:
            tenant_stats[instance["tenant"]]["rds_idle"] += 1
            print(f"ç§Ÿæˆ·: {instance['tenant']:8s} | "
                  f"å®žä¾‹: {instance['instance_name'][:30]:30s} | "
                  f"å¼•æ“Ž: {instance['engine']:15s} | "
                  f"CPU: {instance['avg_cpu']:5.2f}% | "
                  f"è¿žæŽ¥: {instance['avg_connections']:5.0f} | "
                  f"åœ°åŸŸ: {instance['region']}")
        print(f"\næ€»è®¡: {len(rds_idle)} ä¸ªé—²ç½®RDSå®žä¾‹")
    else:
        print("æœªå‘çŽ°é—²ç½®RDSå®žä¾‹")
    
    # 3. SLBé—²ç½®å®žä¾‹
    print("\n" + "="*80)
    print("âš–ï¸  SLBé—²ç½®å®žä¾‹ (è¿‡åŽ»7å¤©å¹³å‡è¿žæŽ¥æ•°<10):")
    print("-"*80)
    slb_idle = get_slb_idle_stats()
    if slb_idle:
        for instance in slb_idle:
            tenant_stats[instance["tenant"]]["slb_idle"] += 1
            print(f"ç§Ÿæˆ·: {instance['tenant']:8s} | "
                  f"åç§°: {instance['lb_name'][:30]:30s} | "
                  f"ç±»åž‹: {instance['address_type']:10s} | "
                  f"è¿žæŽ¥: {instance['avg_connections']:5.0f} | "
                  f"åœ°åŸŸ: {instance['region']}")
        print(f"\næ€»è®¡: {len(slb_idle)} ä¸ªé—²ç½®SLBå®žä¾‹")
    else:
        print("æœªå‘çŽ°é—²ç½®SLBå®žä¾‹")
    
    # 4. DNSåŸŸåç»Ÿè®¡
    print("\n" + "="*80)
    print("ðŸŒ DNSåŸŸåç»Ÿè®¡:")
    print("-"*80)
    dns_data = get_dns_unused_records()
    if dns_data:
        for item in dns_data:
            print(f"ç§Ÿæˆ·: {item['tenant']:8s} | åŸŸå: {item['domain']:40s} | è®°å½•æ•°: {item['record_count']}")
        print(f"\næ€»è®¡: {len(dns_data)} ä¸ªåŸŸå")
    else:
        print("æœªå‘çŽ°DNSè®°å½•")
    
    # æ˜¾ç¤ºæŒ‰ç§Ÿæˆ·æ±‡æ€»
    print("\n" + "="*80)
    print("ðŸ“Š æŒ‰ç§Ÿæˆ·æ±‡æ€»:")
    print("="*80)
    print(f"{'ç§Ÿæˆ·':<10} {'ECSé—²ç½®':<10} {'RDSé—²ç½®':<10} {'SLBé—²ç½®':<10}")
    print("-"*80)
    
    total_ecs = 0
    total_rds = 0
    total_slb = 0
    
    for tenant in sorted(tenant_stats.keys()):
        stats = tenant_stats[tenant]
        print(f"{tenant:<10} {stats['ecs_idle']:<10} {stats['rds_idle']:<10} {stats['slb_idle']:<10}")
        total_ecs += stats['ecs_idle']
        total_rds += stats['rds_idle']
        total_slb += stats['slb_idle']
    
    print("-"*80)
    print(f"{'æ€»è®¡':<10} {total_ecs:<10} {total_rds:<10} {total_slb:<10}")
    print("="*80)
    
    # ç”ŸæˆExcelæŠ¥å‘Š
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    excel_file = f"all_tenants_idle_summary_{timestamp}.xlsx"
    
    try:
        wb = openpyxl.Workbook()
        
        # ECSå·¥ä½œè¡¨
        if ecs_idle:
            ws_ecs = wb.active
            ws_ecs.title = "ECSé—²ç½®å®žä¾‹"
            headers = ["ç§Ÿæˆ·", "å®žä¾‹åç§°", "å®žä¾‹ID", "å®žä¾‹ç±»åž‹", "åœ°åŸŸ", "çŠ¶æ€", "å¹³å‡CPU%", "å¹³å‡å†…å­˜%"]
            ws_ecs.append(headers)
            
            for instance in ecs_idle:
                ws_ecs.append([
                    instance["tenant"],
                    instance["instance_name"],
                    instance["instance_id"],
                    instance["instance_type"],
                    instance["region"],
                    instance["status"],
                    instance["avg_cpu"],
                    instance["avg_memory"]
                ])
        
        # RDSå·¥ä½œè¡¨
        if rds_idle:
            ws_rds = wb.create_sheet("RDSé—²ç½®å®žä¾‹")
            headers = ["ç§Ÿæˆ·", "å®žä¾‹åç§°", "å®žä¾‹ID", "å¼•æ“Ž", "åœ°åŸŸ", "çŠ¶æ€", "å¹³å‡CPU%", "å¹³å‡è¿žæŽ¥æ•°"]
            ws_rds.append(headers)
            
            for instance in rds_idle:
                ws_rds.append([
                    instance["tenant"],
                    instance["instance_name"],
                    instance["instance_id"],
                    instance["engine"],
                    instance["region"],
                    instance["status"],
                    instance["avg_cpu"],
                    instance["avg_connections"]
                ])
        
        # SLBå·¥ä½œè¡¨
        if slb_idle:
            ws_slb = wb.create_sheet("SLBé—²ç½®å®žä¾‹")
            headers = ["ç§Ÿæˆ·", "è´Ÿè½½å‡è¡¡åç§°", "å®žä¾‹ID", "ç±»åž‹", "åœ°åŸŸ", "çŠ¶æ€", "å¹³å‡è¿žæŽ¥æ•°"]
            ws_slb.append(headers)
            
            for instance in slb_idle:
                ws_slb.append([
                    instance["tenant"],
                    instance["lb_name"],
                    instance["lb_id"],
                    instance["address_type"],
                    instance["region"],
                    instance["status"],
                    instance["avg_connections"]
                ])
        
        wb.save(excel_file)
        print(f"\nâœ… ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {excel_file}")
        
    except Exception as e:
        print(f"\nâŒ ç”ŸæˆExcelæŠ¥å‘Šå¤±è´¥: {e}")
    
    print("\n" + "="*80)
    print("âœ… æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
    print("="*80)


if __name__ == "__main__":
    generate_summary_report()
