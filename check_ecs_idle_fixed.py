#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import json
import msgpack
import datetime
import sqlite3
from aliyunsdkcore.client import AcsClient
from aliyunsdkcore.request import CommonRequest
import pandas as pd

# å¯¼å…¥æ–°çš„å·¥å…·æ¨¡å—
try:
    from utils.logger import setup_logger
    from utils.concurrent_helper import process_concurrently
    from utils.retry_helper import retry_api_call
    USE_NEW_UTILS = True
except ImportError:
    # å¦‚æœå·¥å…·æ¨¡å—ä¸å­˜åœ¨ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼
    USE_NEW_UTILS = False
    print("âš ï¸  å·¥å…·æ¨¡å—æœªæ‰¾åˆ°ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼ï¼ˆæ— å¹¶å‘å’Œé‡è¯•ï¼‰")

# é…ç½®ä¿¡æ¯ - å°†ä»mainå‡½æ•°å‚æ•°ä¼ å…¥
access_key_id = None
access_key_secret = None

# æ—¥å¿—è®°å½•å™¨ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
logger = None

def set_credentials(key_id, key_secret):
    """è®¾ç½®è®¿é—®å‡­è¯"""
    global access_key_id, access_key_secret
    access_key_id = key_id
    access_key_secret = key_secret

# æ•°æ®åº“/ç¼“å­˜é…ç½®ï¼ˆé»˜è®¤å…¨å±€ï¼Œè¿è¡Œæ—¶æŒ‰ç§Ÿæˆ·é‡å†™ï¼‰
DB_FILE = "ecs_monitoring_data_fixed.db"
CACHE_FILE = "ecs_data_cache_fixed.pkl"
CACHE_EXPIRE_HOURS = 24

def set_storage_paths(tenant_name: str = None, base_dir: str = "."):
    """æŒ‰ç§Ÿæˆ·è®¾ç½®æ•°æ®åº“ä¸ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    global DB_FILE, CACHE_FILE
    if tenant_name:
        tenant_data_dir = os.path.join(base_dir, "data", tenant_name, "ecs")
    else:
        tenant_data_dir = os.path.join(base_dir, "data", "default", "ecs")
    os.makedirs(tenant_data_dir, exist_ok=True)
    DB_FILE = os.path.join(tenant_data_dir, "ecs_monitoring_data_fixed.db")
    CACHE_FILE = os.path.join(tenant_data_dir, "ecs_data_cache_fixed.pkl")

def init_database():
    """åˆå§‹åŒ–æœ¬åœ°æ•°æ®åº“"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    # åˆ›å»ºå®ä¾‹ä¿¡æ¯è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS instances (
            instance_id TEXT PRIMARY KEY,
            instance_name TEXT,
            region TEXT,
            status TEXT,
            instance_type TEXT,
            creation_time TEXT,
            cpu_cores INTEGER,
            memory_gb INTEGER,
            eip_bandwidth INTEGER,
            eip_address TEXT,
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # åˆ›å»ºç›‘æ§æ•°æ®è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS monitoring_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            instance_id TEXT,
            metric_name TEXT,
            metric_value REAL,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (instance_id) REFERENCES instances (instance_id)
        )
    ''')
    
    # åˆ›å»ºæˆæœ¬æ•°æ®è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS cost_data (
            instance_id TEXT PRIMARY KEY,
            monthly_cost REAL,
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (instance_id) REFERENCES instances (instance_id)
        )
    ''')
    
    conn.commit()
    conn.close()
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

def get_all_regions(client):
    """è·å–æ‰€æœ‰å¯ç”¨åŒºåŸŸ"""
    request = CommonRequest()
    request.set_domain('ecs.aliyuncs.com')
    request.set_method('POST')
    request.set_version('2014-05-26')
    request.set_action_name('DescribeRegions')
    
    response = client.do_action_with_exception(request)
    data = json.loads(response)
    
    regions = []
    for region in data['Regions']['Region']:
        regions.append(region['RegionId'])
    
    return regions

def get_all_instances(client, region_id):
    """è·å–æŒ‡å®šåŒºåŸŸçš„æ‰€æœ‰ECSå®ä¾‹"""
    request = CommonRequest()
    request.set_domain(f'ecs.{region_id}.aliyuncs.com')
    request.set_method('POST')
    request.set_version('2014-05-26')
    request.set_action_name('DescribeInstances')
    request.add_query_param('PageSize', 100)
    
    all_instances = []
    page_number = 1
    
    while True:
        request.add_query_param('PageNumber', page_number)
        response = client.do_action_with_exception(request)
        data = json.loads(response)
        
        if 'Instances' not in data or 'Instance' not in data['Instances']:
            break
            
        instances = data['Instances']['Instance']
        if not isinstance(instances, list):
            instances = [instances]
        
        for instance in instances:
            all_instances.append({
                'InstanceId': instance['InstanceId'],
                'InstanceName': instance.get('InstanceName', 'æœªå‘½å'),
                'Status': instance.get('Status', 'æœªçŸ¥'),
                'InstanceType': instance.get('InstanceType', 'æœªçŸ¥'),
                'CreationTime': instance.get('CreationTime', 'æœªçŸ¥'),
                'Cpu': instance.get('Cpu', 0),
                'Memory': instance.get('Memory', 0)
            })
        
        if len(instances) < 100:
            break
        page_number += 1
    
    return all_instances

def _get_instance_eip_info_internal(client, region_id, instance_id):
    """è·å–å®ä¾‹çš„EIPä¿¡æ¯ï¼ˆå†…éƒ¨å®ç°ï¼‰"""
    request = CommonRequest()
    request.set_domain(f'ecs.{region_id}.aliyuncs.com')
    request.set_method('POST')
    request.set_version('2014-05-26')
    request.set_action_name('DescribeEipAddresses')
    request.add_query_param('AssociatedInstanceId', instance_id)
    
    response = client.do_action_with_exception(request)
    data = json.loads(response)
    
    if 'EipAddresses' in data and 'EipAddress' in data['EipAddresses']:
        eip_list = data['EipAddresses']['EipAddress']
        if not isinstance(eip_list, list):
            eip_list = [eip_list]
        
        if eip_list:
            eip = eip_list[0]
            return {
                'Bandwidth': eip.get('Bandwidth', 0),
                'EipAddress': eip.get('IpAddress', '')
            }
    
    return None


def get_instance_eip_info(client, region_id, instance_id):
    """è·å–å®ä¾‹çš„EIPä¿¡æ¯ï¼ˆå¸¦é‡è¯•ï¼Œä»…å¯¹ç½‘ç»œé”™è¯¯é‡è¯•ï¼‰"""
    def _call():
        return _get_instance_eip_info_internal(client, region_id, instance_id)
    
    if USE_NEW_UTILS:
        # åªå¯¹ç½‘ç»œé”™è¯¯é‡è¯•ï¼Œä¸šåŠ¡é”™è¯¯ï¼ˆ400/403ç­‰ï¼‰ç›´æ¥è¿”å›None
        wrapped_call = retry_api_call(max_attempts=3, retry_exceptions=(ConnectionError, TimeoutError))(_call)
        try:
            return wrapped_call()
        except Exception as e:
            # 400/403ç­‰ä¸šåŠ¡é”™è¯¯ä¸é‡è¯•ï¼Œç›´æ¥è¿”å›None
            error_str = str(e)
            if any(code in error_str for code in ['400', '403', 'Invalid', 'Forbidden']):
                if logger:
                    logger.debug(f"è·å–EIPä¿¡æ¯ä¸šåŠ¡é”™è¯¯ï¼ˆé¢„æœŸï¼‰ {instance_id}: {error_str[:100]}")
            else:
                if logger:
                    logger.warning(f"è·å–EIPä¿¡æ¯å¤±è´¥ {instance_id}: {e}")
            return None
    else:
        try:
            return _get_instance_eip_info_internal(client, region_id, instance_id)
        except Exception as e:
            return None

def get_comprehensive_metrics_from_db(instance_id):
    """ä»æ•°æ®åº“è·å–å®ä¾‹çš„å…¨é¢ç›‘æ§æ•°æ®"""
    conn = sqlite3.connect('ecs_monitoring_data_fixed.db')
    
    # å®šä¹‰éœ€è¦è·å–çš„æŒ‡æ ‡
    metrics_to_get = [
        'CPUåˆ©ç”¨ç‡', 'ç£ç›˜è¯»BPS', 'ç£ç›˜å†™BPS', 'ç£ç›˜è¯»IOPS', 'ç£ç›˜å†™IOPS',
        'ç½‘ç»œè¿æ¥æ•°', 'å…¥ç½‘æµé‡', 'å‡ºç½‘æµé‡', 'å†…å­˜åˆ©ç”¨ç‡', '1åˆ†é’Ÿè´Ÿè½½',
        '5åˆ†é’Ÿè´Ÿè½½', '15åˆ†é’Ÿè´Ÿè½½', 'Load Average', 'TCPè¿æ¥æ•°',
        'å†…ç½‘å…¥å¸¦å®½', 'å†…ç½‘å‡ºå¸¦å®½', 'çŠ¶æ€æ£€æŸ¥', 'ç£ç›˜IOé˜Ÿåˆ—é•¿åº¦'
    ]
    
    result = {}
    
    for metric_name in metrics_to_get:
        try:
            query = '''
            SELECT AVG(metric_value) as avg_value
            FROM monitoring_data 
            WHERE instance_id = ? AND metric_name = ?
            '''
            cursor = conn.cursor()
            cursor.execute(query, (instance_id, metric_name))
            row = cursor.fetchone()
            
            if row and row[0] is not None:
                result[metric_name] = float(row[0])
            else:
                result[metric_name] = 0
        except Exception as e:
            result[metric_name] = 0
    
    conn.close()
    return result

def get_comprehensive_metrics(client, region_id, instance_id, show_progress=False, metric_index=0, total_metrics=18, days: int = 14):
    """è·å–å®ä¾‹çš„å…¨é¢ç›‘æ§æ•°æ®"""
    end_time = int(round(time.time() * 1000))
    # æ”¯æŒå¯é…ç½®çª—å£ï¼ˆé»˜è®¤14å¤©ï¼‰ï¼ŒæŒ‰å°æ—¶èšåˆåå–å¹³å‡
    start_time = end_time - days * 24 * 60 * 60 * 1000
    
    # å®šä¹‰æ‰€æœ‰å¯èƒ½çš„ç›‘æ§æŒ‡æ ‡ - ä¿®å¤ç‰ˆæœ¬
    # åŸºç¡€æŒ‡æ ‡ï¼ˆacs_ecs_dashboardå‘½åç©ºé—´ï¼‰
    base_metrics = {
        'CPUUtilization': ('CPUåˆ©ç”¨ç‡', 'acs_ecs_dashboard'),
        'DiskReadBPS': ('ç£ç›˜è¯»BPS', 'acs_ecs_dashboard'),
        'DiskWriteBPS': ('ç£ç›˜å†™BPS', 'acs_ecs_dashboard'),
        'DiskReadIOPS': ('ç£ç›˜è¯»IOPS', 'acs_ecs_dashboard'),
        'DiskWriteIOPS': ('ç£ç›˜å†™IOPS', 'acs_ecs_dashboard'),
        'ConnectionUtilization': ('ç½‘ç»œè¿æ¥æ•°', 'acs_ecs_dashboard'),
        # æ”¹ä¸ºé»˜è®¤é‡‡é›†å†…ç½‘å¸¦å®½ä½œä¸ºâ€œå…¥ç½‘æµé‡/å‡ºç½‘æµé‡â€
        'IntranetInRate': ('å…¥ç½‘æµé‡', 'acs_ecs_dashboard'),
        'IntranetOutRate': ('å‡ºç½‘æµé‡', 'acs_ecs_dashboard'),
        # å…¬ç½‘å¸¦å®½ä¿ç•™ï¼Œè‹¥éœ€è¦å¯ç”¨äºå¯¹ç…§
        'InternetInRate': ('å…¬ç½‘å…¥å¸¦å®½', 'acs_ecs_dashboard'),
        'InternetOutRate': ('å…¬ç½‘å‡ºå¸¦å®½', 'acs_ecs_dashboard'),
        'StatusCheck': ('çŠ¶æ€æ£€æŸ¥', 'acs_ecs_dashboard'),
        'DiskIOQueueSize': ('ç£ç›˜IOé˜Ÿåˆ—é•¿åº¦', 'acs_ecs_dashboard')
    }
    
    # äº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡ï¼ˆè¿™äº›æŒ‡æ ‡åœ¨acs_ecs_dashboardå‘½åç©ºé—´ä¸­ï¼Œä½¿ç”¨Groupvm.å‰ç¼€ï¼‰
    agent_metrics_main = {
        'Groupvm.MemoryUtilization': ('å†…å­˜åˆ©ç”¨ç‡', 'acs_ecs_dashboard'),
        'load_1m': ('1åˆ†é’Ÿè´Ÿè½½', 'acs_ecs_dashboard'),
        'load_5m': ('5åˆ†é’Ÿè´Ÿè½½', 'acs_ecs_dashboard'),
        'load_15m': ('15åˆ†é’Ÿè´Ÿè½½', 'acs_ecs_dashboard'),
        'Groupvm.LoadAverage': ('Load Average', 'acs_ecs_dashboard'),
        'Groupvm.TcpConnection': ('TCPè¿æ¥æ•°', 'acs_ecs_dashboard')
    }
    
    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡ï¼ˆåŸºç¡€æŒ‡æ ‡ + äº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡ï¼‰
    all_metrics = {**base_metrics, **agent_metrics_main}
    all_metrics_list = list(all_metrics.items())
    
    result = {}
    agent_metrics_found = []  # è®°å½•å“ªäº›äº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡æˆåŠŸè·å–åˆ°æ•°æ®
    
    for idx, (metric_name, (display_name, namespace)) in enumerate(all_metrics_list):
        if show_progress and idx % 6 == 0:  # æ¯6ä¸ªæŒ‡æ ‡æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            progress = (idx / len(all_metrics_list)) * 100
            sys.stdout.write(f'\r    ğŸ“Š è·å–ç›‘æ§æŒ‡æ ‡: {idx}/{len(all_metrics_list)} ({progress:.0f}%)')
            sys.stdout.flush()
        
        try:
            request = CommonRequest()
            request.set_domain(f'cms.{region_id}.aliyuncs.com')
            request.set_method('POST')
            request.set_version('2019-01-01')
            request.set_action_name('DescribeMetricData')
            request.add_query_param('RegionId', region_id)
            request.add_query_param('Namespace', namespace)
            request.add_query_param('MetricName', metric_name)
            request.add_query_param('StartTime', start_time)
            request.add_query_param('EndTime', end_time)
            # ä½¿ç”¨æ¯å°æ—¶ç²’åº¦ï¼Œé¿å…æŒ‰å¤©èšåˆå¯¼è‡´æ— æ•°æ®
            request.add_query_param('Period', '3600')
            request.add_query_param('Dimensions', f'[{{"instanceId":"{instance_id}"}}]')
            
            response = client.do_action_with_exception(request)
            data = json.loads(response)
            
            has_data_points = False
            has_data = False
            if 'Datapoints' in data and data['Datapoints']:
                has_data_points = True  # æœ‰Datapointså­—æ®µï¼Œè¯´æ˜æŒ‡æ ‡å­˜åœ¨
                if isinstance(data['Datapoints'], str):
                    dps = json.loads(data['Datapoints'])
                else:
                    dps = data['Datapoints']
                
                if dps and len(dps) > 0:
                    # è®¡ç®—æ‰€æœ‰æ•°æ®ç‚¹çš„å¹³å‡å€¼ - ç¡®ä¿14å¤©å¹³å‡å€¼
                    total = 0
                    count = 0
                    for dp in dps:
                        if 'Average' in dp and dp['Average'] is not None:
                            total += float(dp['Average'])
                            count += 1
                    
                    if count > 0:
                        result[display_name] = total / count
                        has_data = True
                        # è®°å½•äº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡æ˜¯å¦æˆåŠŸè·å–åˆ°æ•°æ®ï¼ˆå³ä½¿å€¼ä¸º0ä¹Ÿç®—æˆåŠŸï¼‰
                        # æ£€æŸ¥æ˜¯å¦æ˜¯äº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡ï¼ˆé€šè¿‡æŒ‡æ ‡åç§°åˆ¤æ–­ï¼‰
                        if metric_name.startswith('Groupvm.') or metric_name.startswith('load_'):
                            agent_metrics_found.append(display_name)
                    else:
                        result[display_name] = 0
                        # å³ä½¿countä¸º0ï¼Œå¦‚æœhas_data_pointsä¸ºTrueï¼Œä¹Ÿè¯´æ˜æŒ‡æ ‡å­˜åœ¨
                        if (metric_name.startswith('Groupvm.') or metric_name.startswith('load_')) and has_data_points:
                            agent_metrics_found.append(display_name)
                else:
                    result[display_name] = 0
                    # ç©ºæ•°ç»„ä½†æœ‰Datapointså­—æ®µï¼Œä¹Ÿè¯´æ˜æŒ‡æ ‡å­˜åœ¨
                    if (metric_name.startswith('Groupvm.') or metric_name.startswith('load_')) and has_data_points:
                        agent_metrics_found.append(display_name)
            else:
                result[display_name] = 0
        except Exception as e:
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œè®¤ä¸ºè¯¥æŒ‡æ ‡ä¸å­˜åœ¨
            result[display_name] = 0
            # å¦‚æœæ˜¯äº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡çš„å¼‚å¸¸ï¼Œè®°å½•ä¸€ä¸‹ï¼ˆä½†ä¸å½±å“åˆ¤æ–­ï¼‰
            if namespace == 'acs_ecs_dashboard_agent' and show_progress:
                # é™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºé”™è¯¯ï¼Œå› ä¸ºå¯èƒ½æ˜¯æŒ‡æ ‡ä¸å­˜åœ¨
                pass
        
        time.sleep(0.1)  # é¿å…APIé™æµ
    
    if show_progress:
        sys.stdout.write('\r    âœ… ç›‘æ§æŒ‡æ ‡è·å–å®Œæˆ' + ' ' * 30 + '\n')
        sys.stdout.flush()
    
    # æ ‡è®°æ˜¯å¦æœ‰äº‘ç›‘æ§æ’ä»¶ï¼ˆåªè¦æœ‰ä¸€ä¸ªäº‘ç›‘æ§æ’ä»¶æŒ‡æ ‡æˆåŠŸè·å–åˆ°æ•°æ®å°±è®¤ä¸ºæœ‰æ’ä»¶ï¼‰
    # å³ä½¿å€¼å¯èƒ½ä¸º0ï¼Œä½†èƒ½è·å–åˆ°æ•°æ®å°±è¯´æ˜æœ‰æ’ä»¶
    result['_has_agent'] = len(agent_metrics_found) > 0
    
    return result

def _get_instance_monthly_cost_internal(client, region_id, instance_id):
    """è·å–å®ä¾‹çš„æœˆåº¦ç»­è´¹æˆæœ¬ï¼ˆå†…éƒ¨å®ç°ï¼‰"""
    request = CommonRequest()
    request.set_domain(f'ecs.{region_id}.aliyuncs.com')
    request.set_method('POST')
    request.set_version('2014-05-26')
    request.set_action_name('DescribeRenewalPrice')
    request.add_query_param('ResourceId', instance_id)
    request.add_query_param('Period', 1)
    request.add_query_param('PriceUnit', 'Month')
    
    response = client.do_action_with_exception(request)
    data = json.loads(response)
    
    if 'PriceInfo' in data and 'Price' in data['PriceInfo']:
        price_info = data['PriceInfo']['Price']
        if 'TradePrice' in price_info:
            return float(price_info['TradePrice'])
    
    return 0


def get_instance_monthly_cost(client, region_id, instance_id):
    """è·å–å®ä¾‹çš„æœˆåº¦ç»­è´¹æˆæœ¬ï¼ˆå¸¦é‡è¯•ï¼Œä»…å¯¹ç½‘ç»œé”™è¯¯é‡è¯•ï¼‰"""
    def _call():
        return _get_instance_monthly_cost_internal(client, region_id, instance_id)
    
    if USE_NEW_UTILS:
        # åªå¯¹ç½‘ç»œé”™è¯¯é‡è¯•ï¼Œä¸šåŠ¡é”™è¯¯ï¼ˆ400/403ç­‰ï¼‰ç›´æ¥è¿”å›0
        wrapped_call = retry_api_call(max_attempts=3, retry_exceptions=(ConnectionError, TimeoutError))(_call)
        try:
            return wrapped_call()
        except Exception as e:
            # 400/403ç­‰ä¸šåŠ¡é”™è¯¯ä¸é‡è¯•ï¼Œç›´æ¥è¿”å›0ï¼ˆæŒ‰é‡ä»˜è´¹å®ä¾‹ä¼šè¿”å›é”™è¯¯ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼‰
            error_str = str(e)
            if any(code in error_str for code in ['400', '403', 'Invalid', 'Forbidden']):
                if logger:
                    logger.debug(f"è·å–æˆæœ¬ä¿¡æ¯ä¸šåŠ¡é”™è¯¯ï¼ˆæŒ‰é‡ä»˜è´¹å®ä¾‹é¢„æœŸï¼‰ {instance_id}: {error_str[:100]}")
            else:
                if logger:
                    logger.warning(f"è·å–æˆæœ¬ä¿¡æ¯å¤±è´¥ {instance_id}: {e}")
            return 0
    else:
        try:
            return _get_instance_monthly_cost_internal(client, region_id, instance_id)
        except Exception as e:
            return 0

def save_to_database(instance_data, metrics_data, cost_data):
    """ä¿å­˜æ•°æ®åˆ°æœ¬åœ°æ•°æ®åº“"""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()
    
    try:
        # ä¿å­˜å®ä¾‹ä¿¡æ¯
        cursor.execute('''
            INSERT OR REPLACE INTO instances 
            (instance_id, instance_name, region, status, instance_type, 
             creation_time, cpu_cores, memory_gb, eip_bandwidth, eip_address)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            instance_data['InstanceId'],
            instance_data['InstanceName'],
            instance_data['Region'],
            instance_data['Status'],
            instance_data['InstanceType'],
            instance_data['CreationTime'],
            instance_data['Cpu'],
            instance_data['Memory'],
            instance_data.get('EipBandwidth', 0),
            instance_data.get('EipAddress', '')
        ))
        
        # ä¿å­˜ç›‘æ§æ•°æ®
        for metric_name, metric_value in metrics_data.items():
            cursor.execute('''
                INSERT INTO monitoring_data (instance_id, metric_name, metric_value)
                VALUES (?, ?, ?)
            ''', (instance_data['InstanceId'], metric_name, metric_value))
        
        # ä¿å­˜æˆæœ¬æ•°æ®
        cursor.execute('''
            INSERT OR REPLACE INTO cost_data (instance_id, monthly_cost)
            VALUES (?, ?)
        ''', (instance_data['InstanceId'], cost_data))
        
        conn.commit()
    except Exception as e:
        print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {e}")
    finally:
        conn.close()

def is_cache_valid():
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
    if not os.path.exists(CACHE_FILE):
        return False
    
    cache_time = os.path.getmtime(CACHE_FILE)
    current_time = time.time()
    return (current_time - cache_time) < (CACHE_EXPIRE_HOURS * 3600)

def save_cache_data(data):
    """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜ï¼ˆä½¿ç”¨msgpackï¼Œå®‰å…¨é«˜æ•ˆï¼‰"""
    cache_data = {
        'timestamp': time.time(),
        'data': data
    }
    with open(CACHE_FILE, 'wb') as f:
        msgpack.pack(cache_data, f)
    print(f"âœ… æ•°æ®å·²ç¼“å­˜åˆ° {CACHE_FILE}")

def load_cache_data():
    """ä»ç¼“å­˜åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨msgpackï¼Œå®‰å…¨é«˜æ•ˆï¼‰"""
    if not os.path.exists(CACHE_FILE):
        return None
    
    try:
        with open(CACHE_FILE, 'rb') as f:
            cache_data = msgpack.unpack(f, raw=False, strict_map_key=False)
        print(f"âœ… ä»ç¼“å­˜åŠ è½½æ•°æ® (ç¼“å­˜æ—¶é—´: {datetime.datetime.fromtimestamp(cache_data['timestamp']).strftime('%Y-%m-%d %H:%M:%S')})")
        return cache_data['data']
    except Exception as e:
        print(f"âŒ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        return None

def is_instance_idle_with_agent(instance, metrics, eip_info=None):
    """åˆ¤æ–­å®ä¾‹æ˜¯å¦ä¸ºé—²ç½®çŠ¶æ€ï¼ˆæœ‰äº‘ç›‘æ§æ’ä»¶ï¼‰"""
    cpu_cores = instance.get('Cpu', 0)
    
    # è·å–å„é¡¹æŒ‡æ ‡
    cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
    memory_util = metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0)
    load_5m = metrics.get('5åˆ†é’Ÿè´Ÿè½½', 0)
    disk_read_iops = metrics.get('ç£ç›˜è¯»IOPS', 0)
    disk_write_iops = metrics.get('ç£ç›˜å†™IOPS', 0)
    
    # è®¡ç®—æ€»IOPS
    total_iops = disk_read_iops + disk_write_iops
    
    # åˆ¤æ–­æ¡ä»¶
    conditions = []
    
    # 1. Load Averageå¹³å‡ä½äºvCPUæ•°é‡çš„5%
    if cpu_cores > 0 and load_5m > 0:
        load_threshold = cpu_cores * 0.05
        if load_5m < load_threshold:
            conditions.append(f"Load Average({load_5m:.2f}) < vCPU*5%({load_threshold:.2f})")
    
    # 2. å†…å­˜å¹³å‡åˆ©ç”¨ç‡å°äº20%
    if memory_util > 0 and memory_util < 20:
        conditions.append(f"å†…å­˜åˆ©ç”¨ç‡({memory_util:.1f}%) < 20%")
    
    # 3. ç£ç›˜å¹³å‡IOPSå°äº100
    if total_iops < 100:
        conditions.append(f"ç£ç›˜IOPS({total_iops:.0f}) < 100")
    
    # 4. EIPå¸¦å®½ä½¿ç”¨ç‡æ£€æŸ¥ï¼ˆå¦‚æœæœ‰EIPï¼‰
    if eip_info and eip_info.get('Bandwidth', 0) > 0:
        bandwidth_mbps = eip_info['Bandwidth']
        internet_in_rate = metrics.get('å…¥ç½‘æµé‡', 0)
        internet_out_rate = metrics.get('å‡ºç½‘æµé‡', 0)
        total_bandwidth_usage = internet_in_rate + internet_out_rate
        
        # è½¬æ¢ä¸ºMbpsè¿›è¡Œæ¯”è¾ƒ
        bandwidth_usage_mbps = total_bandwidth_usage / 1024 / 1024 * 8  # bpsè½¬Mbps
        bandwidth_threshold = bandwidth_mbps * 0.1  # 10%é˜ˆå€¼
        
        if bandwidth_usage_mbps < bandwidth_threshold:
            conditions.append(f"EIPå¸¦å®½ä½¿ç”¨ç‡({bandwidth_usage_mbps:.2f}Mbps) < å³°å€¼*10%({bandwidth_threshold:.2f}Mbps)")
    
    return len(conditions) > 0, conditions

def is_instance_idle_without_agent(instance, metrics, eip_info=None):
    """åˆ¤æ–­å®ä¾‹æ˜¯å¦ä¸ºé—²ç½®çŠ¶æ€ï¼ˆæ— äº‘ç›‘æ§æ’ä»¶ï¼‰"""
    # è·å–å„é¡¹æŒ‡æ ‡
    cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
    disk_read_iops = metrics.get('ç£ç›˜è¯»IOPS', 0)
    disk_write_iops = metrics.get('ç£ç›˜å†™IOPS', 0)
    
    # è®¡ç®—æ€»IOPS
    total_iops = disk_read_iops + disk_write_iops
    
    # åˆ¤æ–­æ¡ä»¶
    conditions = []
    
    # 1. CPUåˆ©ç”¨ç‡ä½äº5%
    if cpu_util < 5:
        conditions.append(f"CPUåˆ©ç”¨ç‡({cpu_util:.1f}%) < 5%")
    
    # 2. ç£ç›˜IOPSå°äº100
    if total_iops < 100:
        conditions.append(f"ç£ç›˜IOPS({total_iops:.0f}) < 100")
    
    # 3. EIPå¸¦å®½ä½¿ç”¨ç‡æ£€æŸ¥ï¼ˆå¦‚æœæœ‰EIPï¼‰
    if eip_info and eip_info.get('Bandwidth', 0) > 0:
        bandwidth_mbps = eip_info['Bandwidth']
        internet_in_rate = metrics.get('å…¥ç½‘æµé‡', 0)
        internet_out_rate = metrics.get('å‡ºç½‘æµé‡', 0)
        total_bandwidth_usage = internet_in_rate + internet_out_rate
        
        # è½¬æ¢ä¸ºMbpsè¿›è¡Œæ¯”è¾ƒ
        bandwidth_usage_mbps = total_bandwidth_usage / 1024 / 1024 * 8  # bpsè½¬Mbps
        bandwidth_threshold = bandwidth_mbps * 0.1  # 10%é˜ˆå€¼
        
        if bandwidth_usage_mbps < bandwidth_threshold:
            conditions.append(f"EIPå¸¦å®½ä½¿ç”¨ç‡({bandwidth_usage_mbps:.2f}Mbps) < å³°å€¼*10%({bandwidth_threshold:.2f}Mbps)")
    
    return len(conditions) > 0, conditions

def get_optimization_suggestion(instance, metrics, has_agent):
    """è·å–ä¼˜åŒ–å»ºè®®"""
    suggestions = []
    
    if has_agent:
        cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
        memory_util = metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0)
        disk_read_iops = metrics.get('ç£ç›˜è¯»IOPS', 0)
        disk_write_iops = metrics.get('ç£ç›˜å†™IOPS', 0)
        total_iops = disk_read_iops + disk_write_iops
        
        # CPUå’Œå†…å­˜ä½¿ç”¨ç‡ä½ï¼Œå»ºè®®é™é…å®ä¾‹è§„æ ¼
        if cpu_util < 30 and memory_util < 30:
            suggestions.append("å»ºè®®é™é…å®ä¾‹è§„æ ¼")
        
        # ç£ç›˜IOPSä½ï¼Œå»ºè®®é™é…ç£ç›˜è§„æ ¼
        if total_iops < 200:
            suggestions.append("å»ºè®®é™é…ç£ç›˜è§„æ ¼")
    else:
        cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
        disk_read_iops = metrics.get('ç£ç›˜è¯»IOPS', 0)
        disk_write_iops = metrics.get('ç£ç›˜å†™IOPS', 0)
        total_iops = disk_read_iops + disk_write_iops
        
        # CPUä½¿ç”¨ç‡ä½ï¼Œå»ºè®®é™é…å®ä¾‹è§„æ ¼
        if cpu_util < 30:
            suggestions.append("å»ºè®®é™é…å®ä¾‹è§„æ ¼")
        
        # ç£ç›˜IOPSä½ï¼Œå»ºè®®é™é…ç£ç›˜è§„æ ¼
        if total_iops < 200:
            suggestions.append("å»ºè®®é™é…ç£ç›˜è§„æ ¼")
    
    return "; ".join(suggestions) if suggestions else "æ— éœ€ä¼˜åŒ–"

def generate_excel_report(idle_instances, has_agent=True, output_dir="."):
    """ç”ŸæˆExcelæŠ¥å‘Š"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    agent_type = "with_agent" if has_agent else "without_agent"
    filename = os.path.join(output_dir, f"ecs_idle_report_{agent_type}_{timestamp}.xlsx")
    
    # å‡†å¤‡æ•°æ®
    data = []
    for i, instance in enumerate(idle_instances, 1):
        metrics = instance['Metrics']
        eip_info = instance.get('EipInfo')
        
        # ä¿®å¤å†…å­˜å•ä½æ˜¾ç¤º - ç¡®ä¿æ˜¾ç¤ºä¸ºGB
        memory_gb = instance['Memory'] / 1024 if instance['Memory'] > 1024 else instance['Memory']
        
        row = {
            'åºå·': i,
            'å®ä¾‹åç§°': instance['InstanceName'],
            'å®ä¾‹ID': instance['InstanceId'],
            'åŒºåŸŸ': instance['Region'],
            'çŠ¶æ€': instance['Status'],
            'å®ä¾‹ç±»å‹': instance['InstanceType'],
            'åˆ›å»ºæ—¶é—´': instance['CreationTime'],
            'CPUæ ¸å¿ƒæ•°': instance['Cpu'],
            'å†…å­˜(GB)': memory_gb,  # ä¿®å¤ï¼šç¡®ä¿æ˜¾ç¤ºä¸ºGB
            'CPUåˆ©ç”¨ç‡(%)': metrics.get('CPUåˆ©ç”¨ç‡', 0),
            'ç£ç›˜è¯»IOPS': metrics.get('ç£ç›˜è¯»IOPS', 0),
            'ç£ç›˜å†™IOPS': metrics.get('ç£ç›˜å†™IOPS', 0),
            'æ€»ç£ç›˜IOPS': metrics.get('ç£ç›˜è¯»IOPS', 0) + metrics.get('ç£ç›˜å†™IOPS', 0),
            'å…¥ç½‘æµé‡(bps)': metrics.get('å…¥ç½‘æµé‡', 0),
            'å‡ºç½‘æµé‡(bps)': metrics.get('å‡ºç½‘æµé‡', 0),
            'ç½‘ç»œè¿æ¥æ•°': metrics.get('ç½‘ç»œè¿æ¥æ•°', 0),
            'é—²ç½®åŸå› ': '; '.join(instance.get('IdleConditions', [])),
            'ä¼˜åŒ–å»ºè®®': instance.get('Optimization', 'æ— '),
            'ç»­è´¹æœˆæˆæœ¬(Â¥)': instance.get('MonthlyCost', 0)
        }
        
        # å¦‚æœæœ‰äº‘ç›‘æ§æ’ä»¶ï¼Œæ·»åŠ æ›´å¤šæŒ‡æ ‡
        if has_agent:
            row.update({
                'å†…å­˜åˆ©ç”¨ç‡(%)': metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0),
                '5åˆ†é’Ÿè´Ÿè½½': metrics.get('5åˆ†é’Ÿè´Ÿè½½', 0),
                '1åˆ†é’Ÿè´Ÿè½½': metrics.get('1åˆ†é’Ÿè´Ÿè½½', 0),
                '15åˆ†é’Ÿè´Ÿè½½': metrics.get('15åˆ†é’Ÿè´Ÿè½½', 0),
                'Load Average': metrics.get('Load Average', 0),
                'TCPè¿æ¥æ•°': metrics.get('TCPè¿æ¥æ•°', 0),
                'å†…ç½‘å…¥å¸¦å®½(bps)': metrics.get('å†…ç½‘å…¥å¸¦å®½', 0),
                'å†…ç½‘å‡ºå¸¦å®½(bps)': metrics.get('å†…ç½‘å‡ºå¸¦å®½', 0),
                'ç£ç›˜IOé˜Ÿåˆ—é•¿åº¦': metrics.get('ç£ç›˜IOé˜Ÿåˆ—é•¿åº¦', 0)
                # ç§»é™¤ä¸å‡†ç¡®çš„ç£ç›˜åˆ©ç”¨ç‡æŒ‡æ ‡
            })
        
        # EIPä¿¡æ¯
        if eip_info:
            row.update({
                'EIPå¸¦å®½(Mbps)': eip_info.get('Bandwidth', 0),
                'EIPåœ°å€': eip_info.get('EipAddress', '')
            })
        
        data.append(row)
    
    # åˆ›å»ºDataFrameå¹¶ä¿å­˜ä¸ºExcel
    df = pd.DataFrame(data)
    
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='é—²ç½®å®ä¾‹è¯¦æƒ…', index=False)
        
        # è·å–å·¥ä½œè¡¨å¯¹è±¡ä»¥è°ƒæ•´åˆ—å®½
        worksheet = writer.sheets['é—²ç½®å®ä¾‹è¯¦æƒ…']
        for column in worksheet.columns:
            max_length = 0
            column_letter = column[0].column_letter
            for cell in column:
                try:
                    if len(str(cell.value)) > max_length:
                        max_length = len(str(cell.value))
                except:
                    pass
            adjusted_width = min(max_length + 2, 50)
            worksheet.column_dimensions[column_letter].width = adjusted_width
    
    print(f"âœ… ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
    return filename

def generate_html_report(idle_instances, has_agent=True, output_dir="."):
    """ç”ŸæˆHTMLæŠ¥å‘Š"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    agent_type = "with_agent" if has_agent else "without_agent"
    filename = os.path.join(output_dir, f"ecs_idle_report_{agent_type}_{timestamp}.html")
    
    agent_text = "æœ‰äº‘ç›‘æ§æ’ä»¶" if has_agent else "æ— äº‘ç›‘æ§æ’ä»¶"
    
    html_content = f"""
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>é˜¿é‡Œäº‘ECSé—²ç½®å®ä¾‹åˆ†ææŠ¥å‘Š - {agent_text}ç‰ˆæœ¬</title>
        <style>
            body {{
                font-family: 'Microsoft YaHei', Arial, sans-serif;
                margin: 0;
                padding: 20px;
                background-color: #f5f5f5;
                color: #333;
            }}
            .container {{
                max-width: 1400px;
                margin: 0 auto;
                background: white;
                border-radius: 10px;
                box-shadow: 0 4px 6px rgba(0,0,0,0.1);
                overflow: hidden;
            }}
            .header {{
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 30px;
                text-align: center;
            }}
            .header h1 {{
                margin: 0;
                font-size: 2.5em;
                font-weight: 300;
            }}
            .header p {{
                margin: 10px 0 0 0;
                font-size: 1.2em;
                opacity: 0.9;
            }}
            .summary {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                gap: 20px;
                padding: 30px;
                background: #f8f9fa;
            }}
            .summary-card {{
                background: white;
                padding: 20px;
                border-radius: 8px;
                text-align: center;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
            .summary-card h3 {{
                margin: 0 0 10px 0;
                color: #667eea;
                font-size: 2em;
            }}
            .summary-card p {{
                margin: 0;
                color: #666;
                font-size: 1.1em;
            }}
            .table-container {{
                padding: 30px;
                overflow-x: auto;
            }}
            table {{
                width: 100%;
                border-collapse: collapse;
                margin-top: 20px;
                background: white;
                border-radius: 8px;
                overflow: hidden;
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            }}
            th {{
                background: #667eea;
                color: white;
                padding: 15px 10px;
                text-align: left;
                font-weight: 600;
                font-size: 0.9em;
            }}
            td {{
                padding: 12px 10px;
                border-bottom: 1px solid #eee;
                font-size: 0.85em;
            }}
            tr:hover {{
                background-color: #f8f9fa;
            }}
            .metric {{
                font-weight: 600;
                color: #667eea;
            }}
            .low-cpu {{ color: #e74c3c; }}
            .medium-cpu {{ color: #f39c12; }}
            .high-cpu {{ color: #27ae60; }}
            .running {{ color: #27ae60; }}
            .stopped {{ color: #e74c3c; }}
            .footer {{
                background: #2c3e50;
                color: white;
                padding: 20px;
                text-align: center;
                font-size: 0.9em;
            }}
            .footer p {{
                margin: 5px 0;
                opacity: 0.8;
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>é˜¿é‡Œäº‘ECSé—²ç½®å®ä¾‹åˆ†ææŠ¥å‘Š</h1>
                <p>{agent_text}ç‰ˆæœ¬ - ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <div class="summary">
                <div class="summary-card">
                    <h3>{len(idle_instances)}</h3>
                    <p>é—²ç½®å®ä¾‹æ•°é‡</p>
                </div>
                <div class="summary-card">
                    <h3>Â¥{sum(instance.get('MonthlyCost', 0) for instance in idle_instances):.2f}</h3>
                    <p>ç»­è´¹æœˆæˆæœ¬æ€»è®¡</p>
                </div>
                <div class="summary-card">
                    <h3>{agent_text}</h3>
                    <p>ç›‘æ§æ’ä»¶çŠ¶æ€</p>
                </div>
            </div>
            
            <div class="table-container">
                <h2>é—²ç½®å®ä¾‹è¯¦æƒ…</h2>
                <table>
                    <thead>
                        <tr>
                            <th>åºå·</th>
                            <th>å®ä¾‹åç§°</th>
                            <th>åŒºåŸŸ</th>
                            <th>çŠ¶æ€</th>
                            <th>å®ä¾‹ç±»å‹</th>
                            <th>CPUåˆ©ç”¨ç‡</th>
    """
    
    if has_agent:
        html_content += """
                            <th>å†…å­˜åˆ©ç”¨ç‡</th>
                            <th>Load Average</th>
                            <th>ç£ç›˜IOé˜Ÿåˆ—é•¿åº¦</th>
        """
    
    html_content += """
                            <th>ç£ç›˜IOPS</th>
                            <th>é—²ç½®åŸå› </th>
                            <th>ä¼˜åŒ–å»ºè®®</th>
                            <th>ç»­è´¹æœˆæˆæœ¬</th>
                        </tr>
                    </thead>
                    <tbody>
    """
    
    for i, instance in enumerate(idle_instances, 1):
        metrics = instance['Metrics']
        cpu = metrics.get('CPUåˆ©ç”¨ç‡', 0)
        total_disk_io = metrics.get('ç£ç›˜è¯»IOPS', 0) + metrics.get('ç£ç›˜å†™IOPS', 0)
        
        # çŠ¶æ€æ ·å¼
        status_class = "running" if instance['Status'] == 'Running' else "stopped"
        
        # CPUåˆ©ç”¨ç‡æ ·å¼
        if cpu < 5:
            cpu_class = "low-cpu"
        elif cpu < 20:
            cpu_class = "medium-cpu"
        else:
            cpu_class = "high-cpu"
        
        # æˆæœ¬æ˜¾ç¤º
        monthly_cost = instance.get('MonthlyCost', 0)
        cost_display = f"Â¥{monthly_cost:.2f}" if monthly_cost > 0 else "æ— æ•°æ®"
        
        html_content += f"""
                        <tr>
                            <td>{i}</td>
                            <td>{instance['InstanceName']}</td>
                            <td>{instance['Region']}</td>
                            <td><span class="{status_class}">{instance['Status']}</span></td>
                            <td>{instance['InstanceType']}</td>
                            <td><span class="{cpu_class}">{cpu:.2f}%</span></td>
        """
        
        if has_agent:
            html_content += f"""
                            <td><span class="metric">{metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0):.1f}%</span></td>
                            <td><span class="metric">{metrics.get('5åˆ†é’Ÿè´Ÿè½½', 0):.2f}</span></td>
                            <td><span class="metric">{metrics.get('ç£ç›˜IOé˜Ÿåˆ—é•¿åº¦', 0):.2f}</span></td>
            """
        
        html_content += f"""
                            <td><span class="metric">{total_disk_io:.0f}</span></td>
                            <td><span class="metric">{'; '.join(instance.get('IdleConditions', [])[:2])}</span></td>
                            <td><span class="metric">{instance.get('Optimization', 'æ— ')}</span></td>
                            <td><span class="metric">{cost_display}</span></td>
                        </tr>
        """
    
    html_content += """
                    </tbody>
                </table>
            </div>
            
            <div class="footer">
                <p>æŠ¥å‘Šè¯´æ˜ï¼š</p>
                <p>â€¢ æ•°æ®åŸºäºæœ€è¿‘14å¤©çš„å¹³å‡å€¼</p>
                <p>â€¢ é—²ç½®å®ä¾‹åˆ¤æ–­æ ‡å‡†ï¼š</p>
    """
    
    if has_agent:
        html_content += """
                <p>  - Load Averageä½äºvCPU*5% æˆ– å†…å­˜åˆ©ç”¨ç‡ä½äº20% æˆ– ç£ç›˜IOPSä½äº100 æˆ– EIPå¸¦å®½ä½¿ç”¨ç‡ä½äºå³°å€¼*10%</p>
        """
    else:
        html_content += """
                <p>  - CPUåˆ©ç”¨ç‡ä½äº5% æˆ– ç£ç›˜IOPSä½äº100 æˆ– EIPå¸¦å®½ä½¿ç”¨ç‡ä½äºå³°å€¼*10%</p>
        """
    
    html_content += f"""
                <p>â€¢ ç›‘æ§æ’ä»¶çŠ¶æ€: {agent_text}</p>
                <p>â€¢ å»ºè®®å®šæœŸæ£€æŸ¥å¹¶ä¼˜åŒ–è¿™äº›å®ä¾‹çš„é…ç½®æˆ–è€ƒè™‘åœæ­¢æœªä½¿ç”¨çš„å®ä¾‹</p>
            </div>
        </div>
    </body>
    </html>
    """
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
    return filename


def main(tenant_name=None, output_base_dir=".", tenant_config=None):
    """ä¸»å‡½æ•°"""
    global logger
    
    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    if USE_NEW_UTILS:
        log_dir = os.path.join(output_base_dir, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        log_file = os.path.join(log_dir, 'ecs_analysis.log')
        logger = setup_logger(
            name='aliyunidle',
            log_file=log_file,
            level='INFO',
            console=True
        )
        logger.info("=" * 60)
        logger.info("å¯åŠ¨é˜¿é‡Œäº‘ECSé—²ç½®å®ä¾‹åˆ†æç¨‹åºï¼ˆä¼˜åŒ–ç‰ˆ - æ”¯æŒå¹¶å‘å’Œé‡è¯•ï¼‰")
        logger.info("=" * 60)
    
    print("ğŸš€ å¯åŠ¨é˜¿é‡Œäº‘ECSé—²ç½®å®ä¾‹åˆ†æç¨‹åºï¼ˆä¼˜åŒ–ç‰ˆ - æ”¯æŒå¹¶å‘å’Œé‡è¯•ï¼‰")
    print("=" * 60)
    
    # ä»tenant_configæˆ–config.jsonè·å–å‡­è¯
    if tenant_config:
        set_credentials(tenant_config.get('access_key_id'), tenant_config.get('access_key_secret'))
    else:
        # å°è¯•ä»config.jsonè¯»å–
        try:
            import json
            with open('config.json', 'r') as f:
                config = json.load(f)
                if 'default_tenant' in config:
                    default_tenant = config['default_tenant']
                    tenant_config = config['tenants'].get(default_tenant)
                    if tenant_config:
                        set_credentials(tenant_config.get('access_key_id'), tenant_config.get('access_key_secret'))
                else:
                    # å…¼å®¹æ—§æ ¼å¼
                    set_credentials(config.get('access_key_id'), config.get('access_key_secret'))
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è¯»å–é…ç½®: {e}")
            print("âš ï¸ ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆå¦‚æœå·²è®¾ç½®ï¼‰")
    
    if not access_key_id or not access_key_secret:
        print("âŒ æœªè®¾ç½®è®¿é—®å‡­è¯ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    # æŒ‰ç§Ÿæˆ·è®¾ç½®å­˜å‚¨è·¯å¾„ï¼ˆæ•°æ®åº“/ç¼“å­˜ï¼‰
    set_storage_paths(tenant_name, output_base_dir)

    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    if tenant_name:
        output_dir = os.path.join(output_base_dir, tenant_name, "cru")
    else:
        output_dir = os.path.join(output_base_dir, "cru")
    
    os.makedirs(output_dir, exist_ok=True)
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    print("ğŸ“Š æ­¥éª¤1/8: åˆå§‹åŒ–æ•°æ®åº“...")
    init_database()
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ\n")
    
    # æ£€æŸ¥ç¼“å­˜ï¼ˆæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡å¼ºåˆ¶ç¦ç”¨ç¼“å­˜ï¼‰
    print("ğŸ“¦ æ­¥éª¤2/8: æ£€æŸ¥ç¼“å­˜çŠ¶æ€...")
    force_no_cache = os.getenv('ALIYUNIDLE_NO_CACHE') == '1'
    if not force_no_cache and is_cache_valid():
        print("ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ®...")
        cached_data = load_cache_data()
        if cached_data:
            regions_with_ecs = cached_data['regions_with_ecs']
            print(f"âœ… ä»ç¼“å­˜åŠ è½½äº† {len(regions_with_ecs)} ä¸ªåŒºåŸŸçš„ECSå®ä¾‹æ•°æ®")
        else:
            print("âŒ ç¼“å­˜æ•°æ®æŸåï¼Œé‡æ–°è·å–æ•°æ®...")
            cached_data = None
    else:
        if force_no_cache:
            print("ğŸš« å·²ç¦ç”¨ç¼“å­˜ï¼ˆALIYUNIDLE_NO_CACHE=1ï¼‰ï¼Œé‡æ–°è·å–æ•°æ®...")
        else:
            print("ğŸ”„ ç¼“å­˜å·²è¿‡æœŸï¼Œé‡æ–°è·å–æ•°æ®...")
        cached_data = None
    print("âœ… ç¼“å­˜æ£€æŸ¥å®Œæˆ\n")
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç¼“å­˜ï¼Œé‡æ–°è·å–æ•°æ®
    if not cached_data:
        print("ğŸŒ æ­¥éª¤3/8: è·å–æ‰€æœ‰å¯ç”¨åŒºåŸŸ...")
        client = AcsClient(access_key_id, access_key_secret, 'cn-hangzhou')
        all_regions = get_all_regions(client)
        print(f"âœ… è·å–åˆ° {len(all_regions)} ä¸ªå¯ç”¨Region")
        
        # æŒ‡å®šè¦æ£€æŸ¥çš„regionåˆ—è¡¨ï¼Œå¦‚æœä¸ºç©ºåˆ™æ£€æŸ¥æ‰€æœ‰region
        target_regions = []  # ç©ºåˆ—è¡¨è¡¨ç¤ºæ£€æŸ¥æ‰€æœ‰region
        
        if target_regions:
            valid_regions = [r for r in target_regions if r in all_regions]
            invalid_regions = [r for r in target_regions if r not in all_regions]
            if invalid_regions:
                print(f"è­¦å‘Šï¼šä»¥ä¸‹regionæ— æ•ˆï¼Œå°†è¢«å¿½ç•¥: {invalid_regions}")
            regions = valid_regions
            print(f"æŒ‡å®šæ£€æŸ¥ {len(regions)} ä¸ªRegion: {regions}")
        else:
            regions = all_regions
            print(f"å°†æ£€æŸ¥æ‰€æœ‰ {len(regions)} ä¸ªRegion")
        print("âœ… åŒºåŸŸé…ç½®å®Œæˆ\n")
        
        regions_with_ecs = []
        
        # ç¬¬ä¸€éï¼šå¿«é€Ÿæ£€æŸ¥å“ªäº›regionæœ‰ECSå®ä¾‹
        print("ğŸ” æ­¥éª¤4/8: å¿«é€Ÿæ£€æŸ¥å„Regionæ˜¯å¦æœ‰ECSå®ä¾‹...")
        print(f"æ­£åœ¨æ£€æŸ¥ {len(regions)} ä¸ªRegion...")
        for i, region in enumerate(regions, 1):
            try:
                print(f"[{i}/{len(regions)}] æ£€æŸ¥Region: {region}", end=" ")
                region_client = AcsClient(access_key_id, access_key_secret, region)
                instances = get_all_instances(region_client, region)
                if len(instances) > 0:
                    regions_with_ecs.append((region, instances))
                    print(f"- å‘ç° {len(instances)} å°ECSå®ä¾‹")
                else:
                    print("- æ— ECSå®ä¾‹ï¼Œè·³è¿‡")
            except Exception as e:
                print(f"- æ£€æŸ¥å¤±è´¥: {str(e)}")
                continue
        
        print(f"âœ… åŒºåŸŸæ£€æŸ¥å®Œæˆï¼Œæ‰¾åˆ° {len(regions_with_ecs)} ä¸ªæœ‰ECSå®ä¾‹çš„Region\n")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        print("ğŸ’¾ ä¿å­˜æ•°æ®åˆ°ç¼“å­˜...")
        cache_data = {
            'regions_with_ecs': regions_with_ecs,
            'timestamp': time.time()
        }
        save_cache_data(cache_data)
        print("âœ… ç¼“å­˜ä¿å­˜å®Œæˆ\n")
    else:
        regions_with_ecs = cached_data['regions_with_ecs']
        client = AcsClient(access_key_id, access_key_secret, 'cn-hangzhou')
        print("âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œè·³è¿‡åŒºåŸŸæ£€æŸ¥\n")
    
    print(f"ğŸ“‹ æ­¥éª¤5/8: å¼€å§‹è¯¦ç»†æ£€æŸ¥ {len(regions_with_ecs)} ä¸ªRegionçš„ECSå®ä¾‹...")
    
    # é‡‡é›†æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼Œé»˜è®¤14å¤©
    try:
        metrics_days = int(os.getenv('ALIYUNIDLE_DAYS', '14'))
        if metrics_days <= 0:
            metrics_days = 14
    except Exception:
        metrics_days = 14

    # å‡†å¤‡æ‰€æœ‰å®ä¾‹æ•°æ®ï¼ˆç”¨äºå¹¶å‘å¤„ç†ï¼‰
    all_instances_to_process = []
    for region_idx, (region, instances) in enumerate(regions_with_ecs, 1):
        for instance in instances:
            all_instances_to_process.append({
                'region': region,
                'instance': instance,
                'region_idx': region_idx,
                'total_regions': len(regions_with_ecs)
            })
    
    total_instances = len(all_instances_to_process)
    print(f"ğŸ“Š å‡†å¤‡å¹¶å‘å¤„ç† {total_instances} å°ECSå®ä¾‹...")
    
    # å®šä¹‰å•ä¸ªå®ä¾‹å¤„ç†å‡½æ•°
    def process_single_instance(item):
        """å¤„ç†å•ä¸ªå®ä¾‹ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
        region = item['region']
        instance = item['instance']
        iid = instance['InstanceId']
        instance_name = instance['InstanceName']
        
        # ä¸ºæ¯ä¸ªçº¿ç¨‹åˆ›å»ºç‹¬ç«‹çš„å®¢æˆ·ç«¯ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        region_client = AcsClient(access_key_id, access_key_secret, region)
        
        try:
            # è·å–å…¨é¢ç›‘æ§æ•°æ®ï¼ˆä»APIè·å–ï¼‰
            metrics = get_comprehensive_metrics(region_client, region, iid, show_progress=False, days=metrics_days)
            
            # è·å–EIPä¿¡æ¯
            eip_info = get_instance_eip_info(region_client, region, iid)
            
            # è·å–æˆæœ¬ä¿¡æ¯
            monthly_cost = get_instance_monthly_cost(region_client, region, iid)
            
            # å‡†å¤‡å®ä¾‹æ•°æ®
            instance_data = {
                'InstanceId': iid,
                'InstanceName': instance_name,
                'Region': region,
                'Status': instance['Status'],
                'InstanceType': instance['InstanceType'],
                'CreationTime': instance['CreationTime'],
                'Cpu': instance['Cpu'],
                'Memory': instance['Memory'],
                'EipBandwidth': eip_info.get('Bandwidth', 0) if eip_info else 0,
                'EipAddress': eip_info.get('EipAddress', '') if eip_info else ''
            }
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            save_to_database(instance_data, metrics, monthly_cost)
            
            # è¿”å›ç»“æœ
            return {
                'InstanceData': instance_data,
                'Metrics': metrics,
                'EipInfo': eip_info,
                'MonthlyCost': monthly_cost,
                'success': True,
                'instance_name': instance_name
            }
        except Exception as e:
            error_msg = str(e)
            if logger:
                logger.error(f"å¤„ç†å®ä¾‹å¤±è´¥ {instance_name} ({iid}): {error_msg}")
            return {
                'success': False,
                'instance_name': instance_name,
                'error': error_msg
            }
    
    # ä½¿ç”¨å¹¶å‘å¤„ç†
    if USE_NEW_UTILS and total_instances > 1:
        print(f"ğŸš€ ä½¿ç”¨å¹¶å‘å¤„ç†ï¼ˆæœ€å¤š10ä¸ªå¹¶å‘çº¿ç¨‹ï¼‰...")
        if logger:
            logger.info(f"å¼€å§‹å¹¶å‘å¤„ç† {total_instances} å°å®ä¾‹")
        
        # è¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(completed, total):
            progress_pct = completed / total * 100
            sys.stdout.write(f'\rğŸ“Š æ€»è¿›åº¦: {completed}/{total} ({progress_pct:.1f}%)')
            sys.stdout.flush()
        
        # å¹¶å‘å¤„ç†
        results = process_concurrently(
            all_instances_to_process,
            process_single_instance,
            max_workers=10,
            description="ECSå®ä¾‹åˆ†æ",
            progress_callback=progress_callback
        )
        
        # æ•´ç†ç»“æœ
        all_instances_data = []
        success_count = 0
        fail_count = 0
        
        for result in results:
            if result and result.get('success'):
                all_instances_data.append({
                    'InstanceData': result['InstanceData'],
                    'Metrics': result['Metrics'],
                    'EipInfo': result['EipInfo'],
                    'MonthlyCost': result['MonthlyCost']
                })
                success_count += 1
            else:
                fail_count += 1
        
        print(f"\nâœ… å¹¶å‘å¤„ç†å®Œæˆ: æˆåŠŸ {success_count} å°, å¤±è´¥ {fail_count} å°")
        if logger:
            logger.info(f"å¹¶å‘å¤„ç†å®Œæˆ: æˆåŠŸ {success_count} å°, å¤±è´¥ {fail_count} å°")
    else:
        # å…¼å®¹æ¨¡å¼ï¼šä¸²è¡Œå¤„ç†
        if USE_NEW_UTILS:
            print("âš ï¸  å¹¶å‘å·¥å…·å¯ç”¨ï¼Œä½†å®ä¾‹æ•°é‡ä¸º1ï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†")
        
        all_instances_data = []
        processed_count = 0
        
        for region_idx, (region, instances) in enumerate(regions_with_ecs, 1):
            print(f"\n[{region_idx}/{len(regions_with_ecs)}] æ­£åœ¨æ£€æŸ¥Region: {region} ({len(instances)}å°å®ä¾‹)")
            region_client = AcsClient(access_key_id, access_key_secret, region)
            
            for i, instance in enumerate(instances, 1):
                iid = instance['InstanceId']
                instance_name = instance['InstanceName']
                processed_count += 1
                
                # æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
                progress_pct = processed_count / total_instances * 100
                print(f"  [{i}/{len(instances)}] ğŸ“Š æ€»è¿›åº¦: {processed_count}/{total_instances} ({progress_pct:.1f}%) - {instance_name}")
                
                try:
                    # è·å–å…¨é¢ç›‘æ§æ•°æ®ï¼ˆä»APIè·å–ï¼‰
                    print(f"    ğŸ“¡ æ­£åœ¨è·å–ç›‘æ§æ•°æ®...", end="", flush=True)
                    metrics = get_comprehensive_metrics(region_client, region, iid, show_progress=True, days=metrics_days)
                    
                    # è·å–EIPä¿¡æ¯
                    print(f"    ğŸ”— è·å–EIPä¿¡æ¯...", end="", flush=True)
                    eip_info = get_instance_eip_info(region_client, region, iid)
                    print(" âœ…")
                    
                    # è·å–æˆæœ¬ä¿¡æ¯
                    print(f"    ğŸ’° è·å–æˆæœ¬ä¿¡æ¯...", end="", flush=True)
                    monthly_cost = get_instance_monthly_cost(region_client, region, iid)
                    print(" âœ…")
                    
                    # å‡†å¤‡å®ä¾‹æ•°æ®
                    instance_data = {
                        'InstanceId': iid,
                        'InstanceName': instance_name,
                        'Region': region,
                        'Status': instance['Status'],
                        'InstanceType': instance['InstanceType'],
                        'CreationTime': instance['CreationTime'],
                        'Cpu': instance['Cpu'],
                        'Memory': instance['Memory'],
                        'EipBandwidth': eip_info.get('Bandwidth', 0) if eip_info else 0,
                        'EipAddress': eip_info.get('EipAddress', '') if eip_info else ''
                    }
                    
                    # ä¿å­˜åˆ°æ•°æ®åº“
                    print(f"    ğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“...", end="", flush=True)
                    save_to_database(instance_data, metrics, monthly_cost)
                    print(" âœ…")
                    
                    # æ·»åŠ åˆ°æ€»æ•°æ®
                    all_instances_data.append({
                        'InstanceData': instance_data,
                        'Metrics': metrics,
                        'EipInfo': eip_info,
                        'MonthlyCost': monthly_cost
                    })
                    
                    has_agent = "æœ‰æ’ä»¶" if metrics.get('_has_agent', False) else "æ— æ’ä»¶"
                    print(f"    âœ… å®Œæˆ ({has_agent})")
                    
                except Exception as e:
                    print(f"\n    âŒ æ£€æŸ¥å¤±è´¥: {str(e)}")
                
                time.sleep(0.2)  # é¿å…APIé™æµ
    
    print(f"\nâœ… æ­¥éª¤5/8å®Œæˆ: æ•°æ®æ”¶é›†å®Œæˆï¼Œå…±å¤„ç† {len(all_instances_data)} å°å®ä¾‹\n")
    
    # åˆ†æé—²ç½®å®ä¾‹ï¼ˆæœ‰äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬ï¼‰
    print("ğŸ” æ­¥éª¤6/8: åˆ†æé—²ç½®å®ä¾‹ï¼ˆæœ‰äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬ï¼‰...")
    idle_instances_with_agent = []
    
    for data in all_instances_data:
        instance = data['InstanceData']
        metrics = data['Metrics']
        eip_info = data['EipInfo']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰äº‘ç›‘æ§æ’ä»¶æ•°æ®
        # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“æ ‡è®°ï¼Œå¦‚æœæ²¡æœ‰åˆ™é€šè¿‡å€¼åˆ¤æ–­
        has_agent = metrics.get('_has_agent', False)
        if not has_agent:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ ‡è®°ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¿™äº›æŒ‡æ ‡çš„æ•°æ®ï¼ˆå³ä½¿å€¼ä¸º0ï¼‰
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰è¿™äº›æŒ‡æ ‡çš„è®°å½•
            has_agent = (metrics.get('å†…å­˜åˆ©ç”¨ç‡') is not None or 
                        metrics.get('5åˆ†é’Ÿè´Ÿè½½') is not None or 
                        metrics.get('TCPè¿æ¥æ•°') is not None)
        
        if has_agent:
            is_idle, conditions = is_instance_idle_with_agent(instance, metrics, eip_info)
            if is_idle:
                optimization = get_optimization_suggestion(instance, metrics, True)
                idle_instances_with_agent.append({
                    'InstanceId': instance['InstanceId'],
                    'InstanceName': instance['InstanceName'],
                    'Region': instance['Region'],
                    'Status': instance['Status'],
                    'InstanceType': instance['InstanceType'],
                    'CreationTime': instance['CreationTime'],
                    'Cpu': instance['Cpu'],
                    'Memory': instance['Memory'],
                    'Metrics': metrics,
                    'EipInfo': eip_info,
                    'IdleConditions': conditions,
                    'Optimization': optimization,
                    'MonthlyCost': data['MonthlyCost']
                })
    
    print(f"âœ… æœ‰äº‘ç›‘æ§æ’ä»¶é—²ç½®å®ä¾‹: {len(idle_instances_with_agent)} å°")
    
    # åˆ†æé—²ç½®å®ä¾‹ï¼ˆæ— äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬ï¼‰
    print("ğŸ” æ­¥éª¤7/8: åˆ†æé—²ç½®å®ä¾‹ï¼ˆæ— äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬ï¼‰...")
    idle_instances_without_agent = []
    
    for data in all_instances_data:
        instance = data['InstanceData']
        metrics = data['Metrics']
        eip_info = data['EipInfo']
        
        # æ£€æŸ¥æ˜¯å¦æœ‰äº‘ç›‘æ§æ’ä»¶æ•°æ®
        # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“æ ‡è®°ï¼Œå¦‚æœæ²¡æœ‰åˆ™é€šè¿‡å€¼åˆ¤æ–­
        has_agent = metrics.get('_has_agent', False)
        if not has_agent:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ ‡è®°ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰è¿™äº›æŒ‡æ ‡çš„æ•°æ®ï¼ˆå³ä½¿å€¼ä¸º0ï¼‰
            has_agent = (metrics.get('å†…å­˜åˆ©ç”¨ç‡') is not None or 
                        metrics.get('5åˆ†é’Ÿè´Ÿè½½') is not None or 
                        metrics.get('TCPè¿æ¥æ•°') is not None)
        
        if not has_agent:
            is_idle, conditions = is_instance_idle_without_agent(instance, metrics, eip_info)
            if is_idle:
                optimization = get_optimization_suggestion(instance, metrics, False)
                idle_instances_without_agent.append({
                    'InstanceId': instance['InstanceId'],
                    'InstanceName': instance['InstanceName'],
                    'Region': instance['Region'],
                    'Status': instance['Status'],
                    'InstanceType': instance['InstanceType'],
                    'CreationTime': instance['CreationTime'],
                    'Cpu': instance['Cpu'],
                    'Memory': instance['Memory'],
                    'Metrics': metrics,
                    'EipInfo': eip_info,
                    'IdleConditions': conditions,
                    'Optimization': optimization,
                    'MonthlyCost': data['MonthlyCost']
                })
    
    print(f"âœ… æ— äº‘ç›‘æ§æ’ä»¶é—²ç½®å®ä¾‹: {len(idle_instances_without_agent)} å°")
    print("âœ… æ­¥éª¤6-7/8å®Œæˆ: é—²ç½®å®ä¾‹åˆ†æå®Œæˆ\n")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“‹ æ­¥éª¤8/8: ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶...")
    print(f"ğŸ“Š æŠ¥å‘Šç»Ÿè®¡:")
    print(f"  - æœ‰äº‘ç›‘æ§æ’ä»¶é—²ç½®å®ä¾‹: {len(idle_instances_with_agent)} å°")
    print(f"  - æ— äº‘ç›‘æ§æ’ä»¶é—²ç½®å®ä¾‹: {len(idle_instances_without_agent)} å°")
    
    # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶
    generated_files = []
    
    # ç”Ÿæˆæœ‰äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬æŠ¥å‘Š
    if idle_instances_with_agent:
        print(f"\nğŸ“Š ç”Ÿæˆæœ‰äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬æŠ¥å‘Š...")
        print("  - ç”ŸæˆExcelæŠ¥å‘Š...")
        excel_file_with_agent = generate_excel_report(idle_instances_with_agent, has_agent=True, output_dir=output_dir)
        print("  - ç”ŸæˆHTMLæŠ¥å‘Š...")
        html_file_with_agent = generate_html_report(idle_instances_with_agent, has_agent=True, output_dir=output_dir)
        
        generated_files.extend([
            f"âœ… ExcelæŠ¥å‘Š: {excel_file_with_agent}",
            f"âœ… HTMLæŠ¥å‘Š: {html_file_with_agent}"
        ])
        print("âœ… æœ‰äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    else:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰äº‘ç›‘æ§æ’ä»¶çš„é—²ç½®å®ä¾‹ï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆ")
    
    # ç”Ÿæˆæ— äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬æŠ¥å‘Š
    if idle_instances_without_agent:
        print(f"\nğŸ“Š ç”Ÿæˆæ— äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬æŠ¥å‘Š...")
        print("  - ç”ŸæˆExcelæŠ¥å‘Š...")
        excel_file_without_agent = generate_excel_report(idle_instances_without_agent, has_agent=False, output_dir=output_dir)
        print("  - ç”ŸæˆHTMLæŠ¥å‘Š...")
        html_file_without_agent = generate_html_report(idle_instances_without_agent, has_agent=False, output_dir=output_dir)
        
        generated_files.extend([
            f"âœ… ExcelæŠ¥å‘Š: {excel_file_without_agent}",
            f"âœ… HTMLæŠ¥å‘Š: {html_file_without_agent}"
        ])
        print("âœ… æ— äº‘ç›‘æ§æ’ä»¶ç‰ˆæœ¬æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
    else:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ— äº‘ç›‘æ§æ’ä»¶çš„é—²ç½®å®ä¾‹ï¼Œè·³è¿‡æŠ¥å‘Šç”Ÿæˆ")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç¨‹åºæ‰§è¡Œå®Œæˆï¼")
    print("=" * 60)
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - æ•°æ®åº“æ–‡ä»¶: {DB_FILE}")
    print(f"  - ç¼“å­˜æ–‡ä»¶: {CACHE_FILE}")
    for file_info in generated_files:
        print(f"  - {file_info}")
    print("=" * 60)

if __name__ == "__main__":
    main()
