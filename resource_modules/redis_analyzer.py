#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Redisèµ„æºåˆ†ææ¨¡å—
åˆ†æRediså®ä¾‹çš„é—²ç½®æƒ…å†µï¼Œæä¾›ä¼˜åŒ–å»ºè®®
"""

import json
import time
import sqlite3
import pandas as pd
import sys
from datetime import datetime
from aliyunsdkcore.client import AcsClient
from aliyunsdkcore.request import CommonRequest
from aliyunsdkr_kvstore.request.v20150101 import DescribeInstancesRequest
from utils.concurrent_helper import process_concurrently
from utils.logger import get_logger
from utils.error_handler import ErrorHandler


class RedisAnalyzer:
    """Redisèµ„æºåˆ†æå™¨"""
    
    def __init__(self, access_key_id, access_key_secret):
        self.access_key_id = access_key_id
        self.access_key_secret = access_key_secret
        self.db_name = 'redis_monitoring_data.db'
        self.logger = get_logger('redis_analyzer')
        
    def init_database(self):
        """åˆå§‹åŒ–Redisæ•°æ®åº“"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        # åˆ›å»ºRediså®ä¾‹è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS redis_instances (
            instance_id TEXT PRIMARY KEY,
            instance_name TEXT,
            instance_type TEXT,
            engine_version TEXT,
            instance_class TEXT,
            region TEXT,
            status TEXT,
            creation_time TEXT,
            expire_time TEXT,
            monthly_cost REAL DEFAULT 0
        )
        ''')
        
        # åˆ›å»ºRedisç›‘æ§æ•°æ®è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS redis_monitoring_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            instance_id TEXT,
            metric_name TEXT,
            metric_value REAL,
            timestamp INTEGER,
            FOREIGN KEY (instance_id) REFERENCES redis_instances (instance_id)
        )
        ''')
        
        conn.commit()
        conn.close()
        self.logger.info("Redisæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
    
    def get_all_regions(self):
        """è·å–æ‰€æœ‰å¯ç”¨åŒºåŸŸ"""
        client = AcsClient(self.access_key_id, self.access_key_secret, 'cn-hangzhou')
        request = CommonRequest()
        request.set_domain('ecs.cn-hangzhou.aliyuncs.com')
        request.set_method('POST')
        request.set_version('2014-05-26')
        request.set_action_name('DescribeRegions')
        
        response = client.do_action_with_exception(request)
        data = json.loads(response)
        
        regions = []
        for region in data['Regions']['Region']:
            regions.append(region['RegionId'])
        
        return regions
    
    def get_redis_instances(self, region_id):
        """è·å–æŒ‡å®šåŒºåŸŸçš„Rediså®ä¾‹"""
        try:
            client = AcsClient(self.access_key_id, self.access_key_secret, region_id)
            request = DescribeInstancesRequest.DescribeInstancesRequest()
            request.set_PageSize(100)
            
            response = client.do_action_with_exception(request)
            data = json.loads(response)
            
            instances = []
            if 'Instances' in data and 'KVStoreInstance' in data['Instances']:
                for instance in data['Instances']['KVStoreInstance']:
                    instances.append({
                        'InstanceId': instance['InstanceId'],
                        'InstanceName': instance.get('InstanceName', ''),
                        'InstanceType': instance.get('InstanceType', ''),
                        'EngineVersion': instance.get('EngineVersion', ''),
                        'InstanceClass': instance.get('InstanceClass', ''),
                        'InstanceStatus': instance.get('InstanceStatus', ''),
                        'CreateTime': instance.get('CreateTime', ''),
                        'EndTime': instance.get('EndTime', ''),
                        'Region': region_id
                    })
            
            return instances
        except Exception as e:
            error = ErrorHandler.handle_api_error(e, "Redis", region_id)
            ErrorHandler.handle_region_error(e, region_id, "Redis")
            return []
    
    def get_redis_metrics(self, region_id, instance_id):
        """è·å–Rediså®ä¾‹çš„ç›‘æ§æ•°æ®"""
        client = AcsClient(self.access_key_id, self.access_key_secret, region_id)
        end_time = int(round(time.time() * 1000))
        start_time = end_time - 14 * 24 * 60 * 60 * 1000  # 14å¤©å‰
        
        # Redisç›‘æ§æŒ‡æ ‡ï¼ˆä½¿ç”¨æ­£ç¡®çš„æŒ‡æ ‡åç§°ï¼‰
        metrics = {
            'CpuUsage': 'CPUåˆ©ç”¨ç‡',
            'MemoryUsage': 'å†…å­˜åˆ©ç”¨ç‡',
            'ConnectionUsage': 'è¿æ¥æ•°ä½¿ç”¨ç‡',
            'IntranetIn': 'å†…ç½‘å…¥æµé‡',
            'IntranetOut': 'å†…ç½‘å‡ºæµé‡',
            'UsedMemory': 'å·²ä½¿ç”¨å†…å­˜'
        }
        
        result = {}
        
        for metric_name, display_name in metrics.items():
            try:
                request = CommonRequest()
                request.set_domain(f'cms.{region_id}.aliyuncs.com')
                request.set_method('POST')
                request.set_version('2019-01-01')
                request.set_action_name('DescribeMetricData')
                request.add_query_param('RegionId', region_id)
                request.add_query_param('Namespace', 'acs_kvstore')
                request.add_query_param('MetricName', metric_name)
                request.add_query_param('StartTime', start_time)
                request.add_query_param('EndTime', end_time)
                request.add_query_param('Period', '86400')  # 1å¤©èšåˆ
                request.add_query_param('Dimensions', f'[{{"instanceId":"{instance_id}"}}]')
                
                response = client.do_action_with_exception(request)
                data = json.loads(response)
                
                if 'Datapoints' in data and data['Datapoints']:
                    if isinstance(data['Datapoints'], str):
                        dps = json.loads(data['Datapoints'])
                    else:
                        dps = data['Datapoints']
                    
                    if dps and len(dps) > 0:
                        # è®¡ç®—æ‰€æœ‰æ•°æ®ç‚¹çš„å¹³å‡å€¼
                        total = 0
                        count = 0
                        for dp in dps:
                            if 'Average' in dp and dp['Average'] is not None:
                                total += float(dp['Average'])
                                count += 1
                        
                        if count > 0:
                            result[display_name] = total / count
                        else:
                            result[display_name] = 0
                    else:
                        result[display_name] = 0
                else:
                    result[display_name] = 0
            except Exception as e:
                result[display_name] = 0
            
            time.sleep(0.1)  # é¿å…APIé™æµ
        
        return result
    
    def save_redis_data(self, instances_data, monitoring_data):
        """ä¿å­˜Redisæ•°æ®åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()
        
        # ä¿å­˜å®ä¾‹æ•°æ®
        for instance in instances_data:
            cursor.execute('''
            INSERT OR REPLACE INTO redis_instances 
            (instance_id, instance_name, instance_type, engine_version, 
             instance_class, region, status, creation_time, expire_time)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                instance['InstanceId'],
                instance['InstanceName'],
                instance['InstanceType'],
                instance['EngineVersion'],
                instance['InstanceClass'],
                instance['Region'],
                instance['InstanceStatus'],
                instance['CreateTime'],
                instance['EndTime']
            ))
        
        # ä¿å­˜ç›‘æ§æ•°æ®
        for instance_id, metrics in monitoring_data.items():
            for metric_name, metric_value in metrics.items():
                cursor.execute('''
                INSERT INTO redis_monitoring_data 
                (instance_id, metric_name, metric_value, timestamp)
                VALUES (?, ?, ?, ?)
                ''', (instance_id, metric_name, metric_value, int(time.time())))
        
        conn.commit()
        conn.close()
        self.logger.info(f"Redisæ•°æ®ä¿å­˜å®Œæˆ: {len(instances_data)}ä¸ªå®ä¾‹")
    
    def is_redis_idle(self, metrics):
        """åˆ¤æ–­Rediså®ä¾‹æ˜¯å¦é—²ç½®"""
        # Redisé—²ç½®åˆ¤æ–­æ ‡å‡†ï¼ˆæˆ–å…³ç³»ï¼‰
        cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
        memory_util = metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0)
        connection_usage = metrics.get('è¿æ¥æ•°ä½¿ç”¨ç‡', 0)
        intranet_in = metrics.get('å†…ç½‘å…¥æµé‡', 0)
        intranet_out = metrics.get('å†…ç½‘å‡ºæµé‡', 0)
        used_memory = metrics.get('å·²ä½¿ç”¨å†…å­˜', 0)
        
        # é—²ç½®æ¡ä»¶ï¼ˆæ»¡è¶³ä»»ä¸€å³åˆ¤å®šä¸ºé—²ç½®ï¼‰
        idle_conditions = [
            cpu_util < 10,  # CPUåˆ©ç”¨ç‡ä½äº10%
            memory_util < 20,  # å†…å­˜åˆ©ç”¨ç‡ä½äº20%
            connection_usage < 20,  # è¿æ¥æ•°ä½¿ç”¨ç‡ä½äº20%
            intranet_in < 100,  # å†…ç½‘å…¥æµé‡ä½äº100KB/s
            intranet_out < 100,  # å†…ç½‘å‡ºæµé‡ä½äº100KB/s
            used_memory < 10000000  # å·²ä½¿ç”¨å†…å­˜ä½äº10MB
        ]
        
        return any(idle_conditions)
    
    def get_idle_reason(self, metrics):
        """è·å–é—²ç½®åŸå› """
        reasons = []
        
        cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
        memory_util = metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0)
        connection_usage = metrics.get('è¿æ¥æ•°ä½¿ç”¨ç‡', 0)
        intranet_in = metrics.get('å†…ç½‘å…¥æµé‡', 0)
        intranet_out = metrics.get('å†…ç½‘å‡ºæµé‡', 0)
        used_memory = metrics.get('å·²ä½¿ç”¨å†…å­˜', 0)
        
        if cpu_util < 10:
            reasons.append(f"CPUåˆ©ç”¨ç‡({cpu_util:.1f}%) < 10%")
        if memory_util < 20:
            reasons.append(f"å†…å­˜åˆ©ç”¨ç‡({memory_util:.1f}%) < 20%")
        if connection_usage < 20:
            reasons.append(f"è¿æ¥æ•°ä½¿ç”¨ç‡({connection_usage:.1f}%) < 20%")
        if intranet_in < 100:
            reasons.append(f"å†…ç½‘å…¥æµé‡({intranet_in:.0f}KB/s) < 100KB/s")
        if intranet_out < 100:
            reasons.append(f"å†…ç½‘å‡ºæµé‡({intranet_out:.0f}KB/s) < 100KB/s")
        if used_memory < 10000000:
            reasons.append(f"å·²ä½¿ç”¨å†…å­˜({used_memory/1024/1024:.1f}MB) < 10MB")
        
        return "; ".join(reasons)
    
    def get_optimization_suggestion(self, metrics, instance_class):
        """è·å–ä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        cpu_util = metrics.get('CPUåˆ©ç”¨ç‡', 0)
        memory_util = metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0)
        connection_usage = metrics.get('è¿æ¥æ•°ä½¿ç”¨ç‡', 0)
        qps = metrics.get('æ¯ç§’æŸ¥è¯¢æ•°', 0)
        hit_rate = metrics.get('å‘½ä¸­ç‡', 0)
        connected_clients = metrics.get('è¿æ¥å®¢æˆ·ç«¯æ•°', 0)
        instantaneous_ops = metrics.get('ç¬æ—¶æ¯ç§’æ“ä½œæ•°', 0)
        
        if cpu_util < 10 and memory_util < 20:
            suggestions.append("å»ºè®®é™é…å®ä¾‹è§„æ ¼")
        elif cpu_util < 10:
            suggestions.append("å»ºè®®é™é…CPUè§„æ ¼")
        elif memory_util < 20:
            suggestions.append("å»ºè®®é™é…å†…å­˜è§„æ ¼")
        
        if connection_usage < 20:
            suggestions.append("å»ºè®®å‡å°‘æœ€å¤§è¿æ¥æ•°")
        
        if qps < 100 and instantaneous_ops < 50:
            suggestions.append("å»ºè®®ä½¿ç”¨æ›´å°çš„å®ä¾‹ç±»å‹")
        
        if hit_rate < 50:
            suggestions.append("å»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥")
        
        if connected_clients < 10:
            suggestions.append("å»ºè®®æ£€æŸ¥å®¢æˆ·ç«¯è¿æ¥")
        
        return "; ".join(suggestions) if suggestions else "å»ºè®®ä¿æŒå½“å‰é…ç½®"
    
    def get_monthly_cost(self, instance_id, instance_class, region):
        """è·å–Rediså®ä¾‹æœˆæˆæœ¬ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…éœ€è¦è°ƒç”¨BSS APIï¼‰"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è°ƒç”¨DescribeRenewalPrice API
        # æ ¹æ®å®ä¾‹ç±»å‹å’ŒåŒºåŸŸè¿”å›ä¼°ç®—æˆæœ¬
        cost_map = {
            'redis.master.micro.default': 50,
            'redis.master.small.default': 100,
            'redis.master.mid.default': 200,
            'redis.master.large.default': 400,
            'redis.master.xlarge.default': 800,
            'redis.master.2xlarge.default': 1600,
            'redis.master.4xlarge.default': 3200,
            'redis.master.8xlarge.default': 6400,
            'redis.master.16xlarge.default': 12800,
            'redis.master.32xlarge.default': 25600,
        }
        
        return cost_map.get(instance_class, 200)  # é»˜è®¤200å…ƒ
    
    def analyze_redis_resources(self):
        """åˆ†æRedisèµ„æº"""
        self.logger.info("å¼€å§‹Redisèµ„æºåˆ†æ...")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self.init_database()
        
        # è·å–æ‰€æœ‰åŒºåŸŸ
        regions = self.get_all_regions()
        self.logger.info(f"è·å–åˆ° {len(regions)} ä¸ªåŒºåŸŸ")
        
        # å¹¶å‘è·å–æ‰€æœ‰åŒºåŸŸçš„å®ä¾‹
        self.logger.info("å¹¶å‘è·å–æ‰€æœ‰åŒºåŸŸçš„Rediså®ä¾‹...")
        
        def get_region_instances(region_item):
            """è·å–å•ä¸ªåŒºåŸŸçš„å®ä¾‹ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
            region = region_item
            try:
                instances = self.get_redis_instances(region)
                return {'region': region, 'instances': instances}
            except Exception as e:
                self.logger.warning(f"åŒºåŸŸ {region} è·å–å®ä¾‹å¤±è´¥: {e}")
                return {'region': region, 'instances': []}
        
        # å¹¶å‘è·å–æ‰€æœ‰åŒºåŸŸçš„å®ä¾‹
        region_results = process_concurrently(
            regions,
            get_region_instances,
            max_workers=10,
            description="è·å–Rediså®ä¾‹"
        )
        
        # æ•´ç†æ‰€æœ‰å®ä¾‹
        all_instances = []
        for result in region_results:
            if result and result.get('instances'):
                all_instances.extend(result['instances'])
                self.logger.info(f"{result['region']}: {len(result['instances'])} ä¸ªå®ä¾‹")
        
        if not all_instances:
            self.logger.warning("æœªå‘ç°ä»»ä½•Rediså®ä¾‹")
            return []
        
        self.logger.info(f"æ€»å…±è·å–åˆ° {len(all_instances)} ä¸ªRediså®ä¾‹")
        
        # å®šä¹‰å•ä¸ªå®ä¾‹å¤„ç†å‡½æ•°ï¼ˆç”¨äºå¹¶å‘ï¼‰
        def process_single_instance(instance_item):
            """å¤„ç†å•ä¸ªå®ä¾‹ï¼ˆç”¨äºå¹¶å‘ï¼‰"""
            instance = instance_item
            instance_id = instance['InstanceId']
            region = instance['Region']
            
            try:
                metrics = self.get_redis_metrics(region, instance_id)
                return {
                    'success': True,
                    'instance_id': instance_id,
                    'metrics': metrics
                }
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "Redis", region, instance_id)
                ErrorHandler.handle_instance_error(e, instance_id, region, "Redis", continue_on_error=True)
                return {
                    'success': False,
                    'instance_id': instance_id,
                    'metrics': {},
                    'error': str(e)
                }
        
        # å¹¶å‘è·å–ç›‘æ§æ•°æ®
        self.logger.info("å¹¶å‘è·å–ç›‘æ§æ•°æ®ï¼ˆæœ€å¤š10ä¸ªå¹¶å‘çº¿ç¨‹ï¼‰...")
        
        def progress_callback(completed, total):
            progress_pct = completed / total * 100
            sys.stdout.write(f'\rğŸ“Š ç›‘æ§æ•°æ®è¿›åº¦: {completed}/{total} ({progress_pct:.1f}%)')
            sys.stdout.flush()
        
        monitoring_results = process_concurrently(
            all_instances,
            process_single_instance,
            max_workers=10,
            description="Redisç›‘æ§æ•°æ®é‡‡é›†",
            progress_callback=progress_callback
        )
        
          # æ¢è¡Œ
        
        # æ•´ç†ç›‘æ§æ•°æ®
        all_monitoring_data = {}
        success_count = 0
        fail_count = 0
        
        for result in monitoring_results:
            if result and result.get('success'):
                all_monitoring_data[result['instance_id']] = result['metrics']
                success_count += 1
            else:
                if result:
                    instance_id = result.get('instance_id', 'unknown')
                    all_monitoring_data[instance_id] = {}
                    fail_count += 1
        
        self.logger.info(f"ç›‘æ§æ•°æ®è·å–å®Œæˆ: æˆåŠŸ {success_count} ä¸ª, å¤±è´¥ {fail_count} ä¸ª")
        
        # ä¿å­˜æ•°æ®
        self.save_redis_data(all_instances, all_monitoring_data)
        
        # åˆ†æé—²ç½®å®ä¾‹
        idle_instances = []
        for instance in all_instances:
            instance_id = instance['InstanceId']
            metrics = all_monitoring_data.get(instance_id, {})
            
            if self.is_redis_idle(metrics):
                idle_reason = self.get_idle_reason(metrics)
                optimization = self.get_optimization_suggestion(metrics, instance['InstanceClass'])
                monthly_cost = self.get_monthly_cost(instance_id, instance['InstanceClass'], instance['Region'])
                
                idle_instances.append({
                    'å®ä¾‹ID': instance_id,
                    'å®ä¾‹åç§°': instance['InstanceName'],
                    'å®ä¾‹ç±»å‹': instance['InstanceClass'],
                    'å¼•æ“ç‰ˆæœ¬': instance['EngineVersion'],
                    'åŒºåŸŸ': instance['Region'],
                    'çŠ¶æ€': instance['InstanceStatus'],
                    'CPUåˆ©ç”¨ç‡(%)': metrics.get('CPUåˆ©ç”¨ç‡', 0),
                    'å†…å­˜åˆ©ç”¨ç‡(%)': metrics.get('å†…å­˜åˆ©ç”¨ç‡', 0),
                    'è¿æ¥æ•°ä½¿ç”¨ç‡(%)': metrics.get('è¿æ¥æ•°ä½¿ç”¨ç‡', 0),
                    'å†…ç½‘å…¥æµé‡(KB/s)': metrics.get('å†…ç½‘å…¥æµé‡', 0),
                    'å†…ç½‘å‡ºæµé‡(KB/s)': metrics.get('å†…ç½‘å‡ºæµé‡', 0),
                    'å·²ä½¿ç”¨å†…å­˜(MB)': metrics.get('å·²ä½¿ç”¨å†…å­˜', 0) / 1024 / 1024,
                    'é—²ç½®åŸå› ': idle_reason,
                    'ä¼˜åŒ–å»ºè®®': optimization,
                    'æœˆæˆæœ¬(Â¥)': monthly_cost
                })
        
        self.logger.info(f"Redisåˆ†æå®Œæˆ: å‘ç° {len(idle_instances)} ä¸ªé—²ç½®å®ä¾‹")
        return idle_instances
    
    def generate_redis_report(self, idle_instances):
        """ç”ŸæˆRedisæŠ¥å‘Š"""
        if not idle_instances:
            self.logger.warning("æ²¡æœ‰å‘ç°é—²ç½®çš„Rediså®ä¾‹")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ç”ŸæˆExcelæŠ¥å‘Š
        df = pd.DataFrame(idle_instances)
        excel_file = f'redis_idle_report_{timestamp}.xlsx'
        df.to_excel(excel_file, index=False)
        self.logger.info(f"ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {excel_file}")
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_file = f'redis_idle_report_{timestamp}.html'
        self.generate_html_report(idle_instances, html_file)
        self.logger.info(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_cost = sum(instance['æœˆæˆæœ¬(Â¥)'] for instance in idle_instances)
        self.logger.info(f"Redisé—²ç½®å®ä¾‹ç»Ÿè®¡: æ€»æ•°é‡={len(idle_instances)}ä¸ª, æ€»æœˆæˆæœ¬={total_cost:,.2f}å…ƒ, é¢„è®¡å¹´èŠ‚çœ={total_cost * 12:,.2f}å…ƒ")
    
    def generate_html_report(self, idle_instances, filename):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Redisé—²ç½®å®ä¾‹åˆ†ææŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1600px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #2c3e50; text-align: center; margin-bottom: 30px; }}
        .summary {{ background: #ecf0f1; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #e74c3c; color: white; }}
        tr:nth-child(even) {{ background-color: #f2f2f2; }}
        .metric {{ font-weight: bold; color: #e74c3c; }}
        .low-utilization {{ background-color: #fff3cd; }}
        .footer {{ margin-top: 30px; padding: 15px; background: #34495e; color: white; text-align: center; border-radius: 5px; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ”´ Redisé—²ç½®å®ä¾‹åˆ†ææŠ¥å‘Š</h1>
        
        <div class="summary">
            <h3>ğŸ“Š æŠ¥å‘Šæ‘˜è¦</h3>
            <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>é—²ç½®å®ä¾‹æ•°é‡:</strong> {len(idle_instances)} ä¸ª</p>
            <p><strong>æ€»æœˆæˆæœ¬:</strong> {sum(instance['æœˆæˆæœ¬(Â¥)'] for instance in idle_instances):,.2f} å…ƒ</p>
            <p><strong>é¢„è®¡å¹´èŠ‚çœ:</strong> {sum(instance['æœˆæˆæœ¬(Â¥)'] for instance in idle_instances) * 12:,.2f} å…ƒ</p>
        </div>
        
        <table>
            <thead>
                <tr>
                    <th>å®ä¾‹åç§°</th>
                    <th>å®ä¾‹ID</th>
                    <th>å®ä¾‹ç±»å‹</th>
                    <th>å¼•æ“ç‰ˆæœ¬</th>
                    <th>åŒºåŸŸ</th>
                    <th>çŠ¶æ€</th>
                    <th>CPUåˆ©ç”¨ç‡(%)</th>
                    <th>å†…å­˜åˆ©ç”¨ç‡(%)</th>
                    <th>è¿æ¥æ•°ä½¿ç”¨ç‡(%)</th>
                    <th>å†…ç½‘å…¥æµé‡(KB/s)</th>
                    <th>å†…ç½‘å‡ºæµé‡(KB/s)</th>
                    <th>å·²ä½¿ç”¨å†…å­˜(MB)</th>
                    <th>é—²ç½®åŸå› </th>
                    <th>ä¼˜åŒ–å»ºè®®</th>
                    <th>æœˆæˆæœ¬(Â¥)</th>
                </tr>
            </thead>
            <tbody>
"""
        
        for instance in idle_instances:
            html_content += f"""
                <tr>
                    <td>{instance['å®ä¾‹åç§°']}</td>
                    <td>{instance['å®ä¾‹ID']}</td>
                    <td>{instance['å®ä¾‹ç±»å‹']}</td>
                    <td>{instance['å¼•æ“ç‰ˆæœ¬']}</td>
                    <td>{instance['åŒºåŸŸ']}</td>
                    <td>{instance['çŠ¶æ€']}</td>
                    <td><span class="metric">{instance['CPUåˆ©ç”¨ç‡(%)']:.1f}%</span></td>
                    <td><span class="metric">{instance['å†…å­˜åˆ©ç”¨ç‡(%)']:.1f}%</span></td>
                    <td><span class="metric">{instance['è¿æ¥æ•°ä½¿ç”¨ç‡(%)']:.1f}%</span></td>
                    <td><span class="metric">{instance['å†…ç½‘å…¥æµé‡(KB/s)']:.1f}</span></td>
                    <td><span class="metric">{instance['å†…ç½‘å‡ºæµé‡(KB/s)']:.1f}</span></td>
                    <td><span class="metric">{instance['å·²ä½¿ç”¨å†…å­˜(MB)']:.1f}</span></td>
                    <td>{instance['é—²ç½®åŸå› ']}</td>
                    <td>{instance['ä¼˜åŒ–å»ºè®®']}</td>
                    <td>{instance['æœˆæˆæœ¬(Â¥)']:,.2f}</td>
                </tr>
"""
        
        html_content += """
            </tbody>
        </table>
        
        <div class="footer">
            <p>ğŸ“‹ é—²ç½®åˆ¤æ–­æ ‡å‡†: CPUåˆ©ç”¨ç‡ < 10% æˆ– å†…å­˜åˆ©ç”¨ç‡ < 20% æˆ– è¿æ¥æ•°ä½¿ç”¨ç‡ < 20% æˆ– å†…ç½‘å…¥æµé‡ < 100KB/s æˆ– å†…ç½‘å‡ºæµé‡ < 100KB/s æˆ– å·²ä½¿ç”¨å†…å­˜ < 10MB</p>
            <p>ğŸ’¡ å»ºè®®: æ ¹æ®ä¼˜åŒ–å»ºè®®è¿›è¡Œèµ„æºé…ç½®è°ƒæ•´ï¼Œé¢„è®¡å¯èŠ‚çœæˆæœ¬30-50%</p>
        </div>
    </div>
</body>
</html>
"""
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_content)


def main():
    """Redisåˆ†æä¸»å‡½æ•°"""
    # è¯»å–é…ç½®æ–‡ä»¶
    try:
        with open('config.json', 'r') as f:
            config = json.load(f)
        access_key_id = config['access_key_id']
        access_key_secret = config['access_key_secret']
    except FileNotFoundError:
        self.logger.error("é…ç½®æ–‡ä»¶ config.json ä¸å­˜åœ¨")
        return
    
    # åˆ›å»ºRedisåˆ†æå™¨
    analyzer = RedisAnalyzer(access_key_id, access_key_secret)
    
    # åˆ†æRedisèµ„æº
    idle_instances = analyzer.analyze_redis_resources()
    
    # ç”ŸæˆæŠ¥å‘Š
    analyzer.generate_redis_report(idle_instances)


if __name__ == "__main__":
    main()
