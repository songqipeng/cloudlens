#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CDNå†…å®¹åˆ†å‘ç½‘ç»œèµ„æºåˆ†ææ¨¡å—
åˆ†æCDNåŸŸåçš„ä½¿ç”¨æƒ…å†µ,æä¾›ä¼˜åŒ–å»ºè®®
"""

import json
import sqlite3
import sys
from datetime import datetime, timedelta
from typing import Dict, List

import pandas as pd
from aliyunsdkcore.client import AcsClient
from aliyunsdkcore.request import CommonRequest

from core.analyzer_registry import AnalyzerRegistry
from core.base_analyzer import BaseResourceAnalyzer
from utils.concurrent_helper import process_concurrently
from utils.error_handler import ErrorHandler
from utils.logger import get_logger


@AnalyzerRegistry.register("cdn", "CDNåŠ é€Ÿ", "ğŸš€")
class CDNAnalyzer(BaseResourceAnalyzer):
    """CDNèµ„æºåˆ†æå™¨"""

    def __init__(self, access_key_id, access_key_secret, tenant_name=None):
        super().__init__(
            access_key_id=access_key_id,
            access_key_secret=access_key_secret,
            tenant_name=tenant_name or "default",
        )
        self.db_name = "cdn_monitoring_data.db"
        self.logger = get_logger("cdn_analyzer")
        self.init_database()

    def get_resource_type(self) -> str:
        return "cdn"

    def init_database(self):
        """åˆå§‹åŒ–CDNæ•°æ®åº“"""
        conn = sqlite3.connect(self.db_name)
        cursor = conn.cursor()

        cursor.execute(
            """
        CREATE TABLE IF NOT EXISTS cdn_domains (
            domain_name TEXT PRIMARY KEY,
            cdn_type TEXT,
            domain_status TEXT,
            source_type TEXT,
            creation_time TEXT,
            traffic_30d REAL DEFAULT 0,
            requests_30d INTEGER DEFAULT 0,
            hit_rate REAL DEFAULT 0
        )
        """
        )

        conn.commit()
        conn.close()
        self.logger.info("CDNæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    def get_all_regions(self):
        """CDNæ˜¯å…¨å±€æœåŠ¡,è¿”å›å…¨çƒ"""
        return ["global"]

    def get_instances(self, region: str) -> List[Dict]:
        """è·å–CDNåŸŸååˆ—è¡¨"""
        return self.get_cdn_domains()

    def get_cdn_domains(self):
        """è·å–CDNåŸŸååˆ—è¡¨"""
        try:
            # CDN APIä½¿ç”¨ä¸åŒçš„endpoint
            client = AcsClient(self.access_key_id, self.access_key_secret, "cn-hangzhou")
            request = CommonRequest()
            request.set_domain("cdn.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2018-05-10")
            request.set_action_name("DescribeUserDomains")
            request.add_query_param("PageSize", "50")
            request.add_query_param("PageNumber", "1")

            all_domains = []
            page_number = 1

            while True:
                request.add_query_param("PageNumber", str(page_number))
                response = client.do_action_with_exception(request)
                data = json.loads(response)

                if "Domains" in data and "PageData" in data["Domains"]:
                    domains = data["Domains"]["PageData"]

                    if not domains:
                        break

                    for domain in domains:
                        all_domains.append(
                            {
                                "DomainName": domain["DomainName"],
                                "CdnType": domain.get("CdnType", ""),
                                "DomainStatus": domain.get("DomainStatus", ""),
                                "SourceType": domain.get("SourceType", ""),
                                "GmtCreated": domain.get("GmtCreated", ""),
                                "GmtModified": domain.get("GmtModified", ""),
                            }
                        )

                    total_count = data.get("TotalCount", 0)
                    if len(all_domains) >= total_count:
                        break

                    page_number += 1
                else:
                    break

            return all_domains
        except Exception as e:
            self.logger.info(f"è·å–CDNåŸŸåå¤±è´¥: {str(e)}")
            return []

    def get_metrics(self, region: str, instance_id: str, days: int = 30) -> Dict:
        """è·å–CDNåŸŸåçš„ç›‘æ§æ•°æ®"""
        domain_name = instance_id
        client = AcsClient(self.access_key_id, self.access_key_secret, "cn-hangzhou")
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)

        result = {}

        # è·å–æµé‡æ•°æ®
        try:
            request = CommonRequest()
            request.set_domain("cdn.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2018-05-10")
            request.set_action_name("DescribeDomainBpsData")
            request.add_query_param("DomainName", domain_name)
            request.add_query_param("StartTime", start_time.strftime("%Y-%m-%dT%H:%M:%SZ"))
            request.add_query_param("EndTime", end_time.strftime("%Y-%m-%dT%H:%M:%SZ"))

            response = client.do_action_with_exception(request)
            data = json.loads(response)

            if "BpsDataPerInterval" in data and "DataModule" in data["BpsDataPerInterval"]:
                bps_data = data["BpsDataPerInterval"]["DataModule"]
                if bps_data:
                    # è®¡ç®—å¹³å‡å¸¦å®½å’Œæ€»æµé‡
                    avg_bps = sum(float(d.get("Value", 0)) for d in bps_data) / len(bps_data)
                    # ä¼°ç®—æ€»æµé‡ (GB) = å¹³å‡å¸¦å®½(bps) * æ—¶é—´(ç§’) / 8 / 1024^3
                    total_traffic_gb = (avg_bps * days * 86400) / 8 / (1024 ** 3)
                    result["å¹³å‡å¸¦å®½(Mbps)"] = avg_bps / (1024 * 1024)
                    result["æ€»æµé‡(GB)"] = total_traffic_gb
                else:
                    result["å¹³å‡å¸¦å®½(Mbps)"] = 0
                    result["æ€»æµé‡(GB)"] = 0
            else:
                result["å¹³å‡å¸¦å®½(Mbps)"] = 0
                result["æ€»æµé‡(GB)"] = 0
        except Exception as e:
            self.logger.debug(f"è·å–å¸¦å®½æ•°æ®å¤±è´¥: {e}")
            result["å¹³å‡å¸¦å®½(Mbps)"] = 0
            result["æ€»æµé‡(GB)"] = 0

        # è·å–è®¿é—®é‡
        try:
            request = CommonRequest()
            request.set_domain("cdn.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2018-05-10")
            request.set_action_name("DescribeDomainPvData")
            request.add_query_param("DomainName", domain_name)
            request.add_query_param("StartTime", start_time.strftime("%Y-%m-%dT%H:%M:%SZ"))
            request.add_query_param("EndTime", end_time.strftime("%Y-%m-%dT%H:%M:%SZ"))

            response = client.do_action_with_exception(request)
            data = json.loads(response)

            if "PvDataInterval" in data and "UsageData" in data["PvDataInterval"]:
                pv_data = data["PvDataInterval"]["UsageData"]
                total_pv = sum(int(d.get("Value", 0)) for d in pv_data)
                result["æ€»è®¿é—®é‡"] = total_pv
            else:
                result["æ€»è®¿é—®é‡"] = 0
        except Exception as e:
            self.logger.debug(f"è·å–è®¿é—®é‡å¤±è´¥: {e}")
            result["æ€»è®¿é—®é‡"] = 0

        # è·å–ç¼“å­˜å‘½ä¸­ç‡
        try:
            request = CommonRequest()
            request.set_domain("cdn.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2018-05-10")
            request.set_action_name("DescribeDomainHitRateData")
            request.add_query_param("DomainName", domain_name)
            request.add_query_param("StartTime", start_time.strftime("%Y-%m-%dT%H:%M:%SZ"))
            request.add_query_param("EndTime", end_time.strftime("%Y-%m-%dT%H:%M:%SZ"))

            response = client.do_action_with_exception(request)
            data = json.loads(response)

            if "HitRateInterval" in data and "DataModule" in data["HitRateInterval"]:
                hit_data = data["HitRateInterval"]["DataModule"]
                if hit_data:
                    avg_hit_rate = sum(float(d.get("Value", 0)) for d in hit_data) / len(hit_data)
                    result["ç¼“å­˜å‘½ä¸­ç‡(%)"] = avg_hit_rate
                else:
                    result["ç¼“å­˜å‘½ä¸­ç‡(%)"] = 0
            else:
                result["ç¼“å­˜å‘½ä¸­ç‡(%)"] = 0
        except Exception as e:
            self.logger.debug(f"è·å–å‘½ä¸­ç‡å¤±è´¥: {e}")
            result["ç¼“å­˜å‘½ä¸­ç‡(%)"] = 0

        # è·å–å›æºå¸¦å®½
        try:
            request = CommonRequest()
            request.set_domain("cdn.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2018-05-10")
            request.set_action_name("DescribeDomainSrcBpsData")
            request.add_query_param("DomainName", domain_name)
            request.add_query_param("StartTime", start_time.strftime("%Y-%m-%dT%H:%M:%SZ"))
            request.add_query_param("EndTime", end_time.strftime("%Y-%m-%dT%H:%M:%SZ"))

            response = client.do_action_with_exception(request)
            data = json.loads(response)

            if "SrcBpsDataPerInterval" in data and "DataModule" in data["SrcBpsDataPerInterval"]:
                src_bps_data = data["SrcBpsDataPerInterval"]["DataModule"]
                if src_bps_data:
                    avg_src_bps = sum(float(d.get("Value", 0)) for d in src_bps_data) / len(src_bps_data)
                    result["å›æºå¸¦å®½(Mbps)"] = avg_src_bps / (1024 * 1024)
                else:
                    result["å›æºå¸¦å®½(Mbps)"] = 0
            else:
                result["å›æºå¸¦å®½(Mbps)"] = 0
        except Exception as e:
            self.logger.debug(f"è·å–å›æºå¸¦å®½å¤±è´¥: {e}")
            result["å›æºå¸¦å®½(Mbps)"] = 0

        # è®¡ç®—å›æºæ¯”ä¾‹
        total_bw = result.get("å¹³å‡å¸¦å®½(Mbps)", 0)
        src_bw = result.get("å›æºå¸¦å®½(Mbps)", 0)
        if total_bw > 0:
            result["å›æºæ¯”ä¾‹(%)"] = (src_bw / total_bw) * 100
        else:
            result["å›æºæ¯”ä¾‹(%)"] = 0

        return result

    def is_idle(self, instance: Dict, metrics: Dict, thresholds: Dict = None) -> tuple:
        """åˆ¤æ–­CDNåŸŸåæ˜¯å¦é—²ç½®"""
        if thresholds is None:
            thresholds = {
                "traffic_gb_min": 1,  # 30å¤©æµé‡ < 1GB
                "requests_min": 1000,  # 30å¤©è®¿é—®é‡ < 1000æ¬¡
                "hit_rate_min": 50,  # ç¼“å­˜å‘½ä¸­ç‡ < 50%
                "back_source_max": 80,  # å›æºæ¯”ä¾‹ > 80%
            }

        issues = []

        # æµé‡æä½
        traffic = metrics.get("æ€»æµé‡(GB)", 0)
        if traffic < thresholds["traffic_gb_min"]:
            issues.append(f"30å¤©æµé‡({traffic:.2f}GB) < {thresholds['traffic_gb_min']}GB")

        # è®¿é—®é‡æä½
        requests = metrics.get("æ€»è®¿é—®é‡", 0)
        if requests < thresholds["requests_min"]:
            issues.append(f"30å¤©è®¿é—®é‡({requests}) < {thresholds['requests_min']}")

        # ç¼“å­˜å‘½ä¸­ç‡ä½
        hit_rate = metrics.get("ç¼“å­˜å‘½ä¸­ç‡(%)", 0)
        if hit_rate > 0 and hit_rate < thresholds["hit_rate_min"]:
            issues.append(f"ç¼“å­˜å‘½ä¸­ç‡({hit_rate:.1f}%) < {thresholds['hit_rate_min']}%")

        # å›æºæ¯”ä¾‹è¿‡é«˜
        back_source = metrics.get("å›æºæ¯”ä¾‹(%)", 0)
        if back_source > thresholds["back_source_max"]:
            issues.append(f"å›æºæ¯”ä¾‹({back_source:.1f}%) > {thresholds['back_source_max']}%")

        # åŸŸåçŠ¶æ€
        domain_status = instance.get("DomainStatus", "")
        if domain_status in ["offline", "configure_failed"]:
            issues.append(f"åŸŸåçŠ¶æ€å¼‚å¸¸: {domain_status}")

        return len(issues) > 0, issues

    def get_optimization_suggestions(self, instance: Dict, metrics: Dict) -> str:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        suggestions = []

        traffic = metrics.get("æ€»æµé‡(GB)", 0)
        requests = metrics.get("æ€»è®¿é—®é‡", 0)
        hit_rate = metrics.get("ç¼“å­˜å‘½ä¸­ç‡(%)", 0)
        back_source = metrics.get("å›æºæ¯”ä¾‹(%)", 0)

        if traffic < 0.1:
            suggestions.append("æµé‡æä½,å»ºè®®è¯„ä¼°æ˜¯å¦éœ€è¦ä¿ç•™CDNåŠ é€Ÿ")

        if requests < 100:
            suggestions.append("è®¿é—®é‡æä½,å»ºè®®åˆ é™¤é—²ç½®åŸŸå")

        if hit_rate < 50 and hit_rate > 0:
            suggestions.append(f"ç¼“å­˜å‘½ä¸­ç‡ä½({hit_rate:.1f}%),å»ºè®®ä¼˜åŒ–ç¼“å­˜é…ç½®")

        if back_source > 80:
            suggestions.append(f"å›æºæ¯”ä¾‹è¿‡é«˜({back_source:.1f}%),å»ºè®®æ£€æŸ¥ç¼“å­˜è§„åˆ™")

        if not suggestions:
            suggestions.append("CDNä½¿ç”¨æ­£å¸¸")

        return "; ".join(suggestions)

    def analyze(self, regions=None, days=30):
        """åˆ†æèµ„æº"""
        self.analyze_cdn_domains()
        return []

    def generate_report(self, idle_instances):
        """ç”ŸæˆæŠ¥å‘Š"""
        pass

    def analyze_cdn_domains(self):
        """åˆ†æCDNåŸŸå"""
        self.logger.info("å¼€å§‹CDNèµ„æºåˆ†æ...")

        domains = self.get_cdn_domains()

        if not domains:
            self.logger.warning("æœªå‘ç°ä»»ä½•CDNåŸŸå")
            return

        self.logger.info(f"æ€»å…±è·å–åˆ° {len(domains)} ä¸ªCDNåŸŸå")

        def process_single_domain(domain_item):
            domain = domain_item
            domain_name = domain["DomainName"]

            try:
                metrics = self.get_metrics("global", domain_name)
                has_issues, issues = self.is_idle(domain, metrics)
                optimization = self.get_optimization_suggestions(domain, metrics)

                domain["metrics"] = metrics
                domain["has_issues"] = has_issues
                domain["issues"] = issues
                domain["optimization"] = optimization

                return {"success": True, "domain": domain}
            except Exception as e:
                ErrorHandler.handle_instance_error(e, domain_name, "global", "CDN", continue_on_error=True)
                return {"success": False, "domain": domain, "error": str(e)}

        def progress_callback(completed, total):
            sys.stdout.write(f"\rğŸ“Š å¤„ç†è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%)")
            sys.stdout.flush()

        processing_results = process_concurrently(
            domains, process_single_domain, max_workers=5, description="CDNåˆ†æ", progress_callback=progress_callback
        )

        analyzed_domains = [r["domain"] for r in processing_results if r and r.get("success")]
        
        self.logger.info(f"\nå¤„ç†å®Œæˆ: æˆåŠŸ {len(analyzed_domains)} ä¸ª")
        self.generate_cdn_report(analyzed_domains)
        self.logger.info("CDNåˆ†æå®Œæˆ")

    def generate_cdn_report(self, domains):
        """ç”ŸæˆCDNæŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        problem_domains = [d for d in domains if d.get("has_issues", False)]

        self.logger.info(f"åˆ†æç»“æœ: å…± {len(domains)} ä¸ªCDNåŸŸåï¼Œå…¶ä¸­ {len(problem_domains)} ä¸ªéœ€è¦ä¼˜åŒ–")

        if not problem_domains:
            self.logger.info("æ²¡æœ‰å‘ç°éœ€è¦ä¼˜åŒ–çš„CDNåŸŸå")
            return

        html_file = f"cdn_analysis_report_{timestamp}.html"
        excel_file = f"cdn_analysis_report_{timestamp}.xlsx"
        
        self.generate_html_report(problem_domains, html_file)
        self.generate_excel_report(problem_domains, excel_file)

        self.logger.info(f"ğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}, {excel_file}")

    def generate_html_report(self, problem_domains, filename):
        """ç”ŸæˆHTMLæŠ¥å‘Š"""
        html = f"""<!DOCTYPE html>
<html><head><meta charset="UTF-8"><title>CDNåŸŸååˆ†ææŠ¥å‘Š</title>
<style>body{{font-family:'Microsoft YaHei',Arial;margin:20px;background:#f5f5f5}}
.container{{max-width:1400px;margin:0 auto;background:white;padding:20px;border-radius:10px}}
h1{{color:#2c3e50;text-align:center;border-bottom:3px solid #e74c3c;padding-bottom:20px}}
table{{width:100%;border-collapse:collapse;margin:20px 0;font-size:14px}}
th,td{{border:1px solid #ddd;padding:10px;text-align:left}}
th{{background:#3498db;color:white}}tr:hover{{background:#e8f4f8}}</style>
</head><body><div class="container"><h1>ğŸš€ CDNåŸŸååˆ†ææŠ¥å‘Š</h1>
<p><strong>ç”Ÿæˆæ—¶é—´:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
<p><strong>éœ€è¦ä¼˜åŒ–çš„åŸŸå:</strong> {len(problem_domains)} ä¸ª</p>
<table><thead><tr><th>åŸŸå</th><th>ç±»å‹</th><th>çŠ¶æ€</th><th>æµé‡(GB)</th><th>è®¿é—®é‡</th><th>å‘½ä¸­ç‡%</th><th>å›æºç‡%</th><th>é—®é¢˜</th><th>å»ºè®®</th></tr></thead><tbody>"""
        
        for domain in problem_domains:
            m = domain.get("metrics", {})
            html += f"""<tr><td>{domain['DomainName']}</td><td>{domain.get('CdnType','')}</td><td>{domain.get('DomainStatus','')}</td>
<td>{m.get('æ€»æµé‡(GB)',0):.2f}</td><td>{m.get('æ€»è®¿é—®é‡',0)}</td><td>{m.get('ç¼“å­˜å‘½ä¸­ç‡(%)',0):.1f}</td><td>{m.get('å›æºæ¯”ä¾‹(%)',0):.1f}</td>
<td>{'; '.join(domain.get('issues',[]))}</td><td>{domain.get('optimization','')}</td></tr>"""
        
        html += "</tbody></table></div></body></html>"
        
        with open(filename, "w", encoding="utf-8") as f:
            f.write(html)

    def generate_excel_report(self, problem_domains, filename):
        """ç”ŸæˆExcelæŠ¥å‘Š"""
        try:
            data = []
            for domain in problem_domains:
                m = domain.get("metrics", {})
                data.append({
                    "åŸŸå": domain["DomainName"],
                    "CDNç±»å‹": domain.get("CdnType", ""),
                    "åŸŸåçŠ¶æ€": domain.get("DomainStatus", ""),
                    "æºç«™ç±»å‹": domain.get("SourceType", ""),
                    "30å¤©æµé‡(GB)": round(m.get("æ€»æµé‡(GB)", 0), 2),
                    "30å¤©è®¿é—®é‡": m.get("æ€»è®¿é—®é‡", 0),
                    "å¹³å‡å¸¦å®½(Mbps)": round(m.get("å¹³å‡å¸¦å®½(Mbps)", 0), 2),
                    "ç¼“å­˜å‘½ä¸­ç‡(%)": round(m.get("ç¼“å­˜å‘½ä¸­ç‡(%)", 0), 1),
                    "å›æºæ¯”ä¾‹(%)": round(m.get("å›æºæ¯”ä¾‹(%)", 0), 1),
                    "é—®é¢˜": "; ".join(domain.get("issues", [])),
                    "ä¼˜åŒ–å»ºè®®": domain.get("optimization", ""),
                })
            
            df = pd.DataFrame(data)
            df.to_excel(filename, index=False, engine="openpyxl")
        except ImportError:
            self.logger.warning("pandasæœªå®‰è£…")


if __name__ == "__main__":
    pass
