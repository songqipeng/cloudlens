#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ECIèµ„æºåˆ†ææ¨¡å—
åˆ†æé˜¿é‡Œäº‘ECIå¼¹æ€§å®¹å™¨å®ä¾‹çš„é—²ç½®æƒ…å†µ
"""

import json
import sys
import time
from datetime import datetime

from aliyunsdkcore.client import AcsClient
from aliyunsdkcore.request import CommonRequest

from cloudlens.core.analyzer_registry import AnalyzerRegistry
from cloudlens.core.base_analyzer import BaseResourceAnalyzer
from cloudlens.core.db_manager import DatabaseManager
from cloudlens.core.report_generator import ReportGenerator
from cloudlens.utils.concurrent_helper import process_concurrently
from cloudlens.utils.error_handler import ErrorHandler
from cloudlens.utils.logger import get_logger


@AnalyzerRegistry.register("eci", "ECIå¼¹æ€§å®¹å™¨å®ä¾‹", "ğŸ³")
class ECIAnalyzer(BaseResourceAnalyzer):
    """ECIèµ„æºåˆ†æå™¨"""

    def __init__(self, access_key_id, access_key_secret, tenant_name=None):
        super().__init__(
            access_key_id=access_key_id,
            access_key_secret=access_key_secret,
            tenant_name=tenant_name or "default",
        )
        self.db_name = "eci_monitoring_data.db"
        self.logger = get_logger("eci_analyzer")
        self.db_manager = DatabaseManager(self.db_name)

    def get_resource_type(self) -> str:
        return "eci"

    def init_database(self):
        """åˆå§‹åŒ–ECIæ•°æ®åº“"""
        extra_columns = {"cpu": "REAL", "memory": "REAL", "instance_type": "TEXT"}
        self.db_manager.create_resource_table("eci", extra_columns)
        self.db_manager.create_monitoring_table("eci")
        self.logger.info("ECIæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    def get_all_regions(self):
        """è·å–æ‰€æœ‰å¯ç”¨åŒºåŸŸ"""
        client = AcsClient(self.access_key_id, self.access_key_secret, "cn-hangzhou")
        request = CommonRequest()
        request.set_domain("ecs.cn-hangzhou.aliyuncs.com")
        request.set_method("POST")
        request.set_version("2014-05-26")
        request.set_action_name("DescribeRegions")
        response = client.do_action_with_exception(request)
        data = json.loads(response)
        return [region["RegionId"] for region in data["Regions"]["Region"]]

    def get_instances(self, region: str):
        """è·å–æŒ‡å®šåŒºåŸŸçš„ECIå®¹å™¨ç»„ (BaseResourceAnalyzeræ¥å£)"""
        return self.get_eci_container_groups(region)

    def get_eci_container_groups(self, region_id):
        """è·å–æŒ‡å®šåŒºåŸŸçš„ECIå®¹å™¨ç»„"""
        try:
            client = AcsClient(self.access_key_id, self.access_key_secret, region_id)
            request = CommonRequest()
            request.set_domain(f"eci.{region_id}.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2018-08-28")
            request.set_action_name("DescribeContainerGroups")
            request.add_query_param("PageSize", 50)
            request.add_query_param("PageNumber", 1)

            all_groups = []
            page_number = 1

            while True:
                request.add_query_param("PageNumber", page_number)
                response = client.do_action_with_exception(request)
                data = json.loads(response)

                if "ContainerGroups" in data and "ContainerGroup" in data["ContainerGroups"]:
                    groups = data["ContainerGroups"]["ContainerGroup"]
                    if not isinstance(groups, list):
                        groups = [groups]

                    if len(groups) == 0:
                        break

                    for group in groups:
                        all_groups.append(
                            {
                                "ContainerGroupId": group.get("ContainerGroupId", ""),
                                "ContainerGroupName": group.get("ContainerGroupName", ""),
                                "RegionId": group.get("RegionId", region_id),
                                "Status": group.get("Status", ""),
                                "Cpu": group.get("Cpu", 0),
                                "Memory": group.get("Memory", 0),
                                "InstanceType": group.get("InstanceType", ""),
                                "CreationTime": group.get("CreationTime", ""),
                            }
                        )

                    page_number += 1
                    if len(groups) < 50:
                        break
                else:
                    break

            return all_groups
        except Exception as e:
            error = ErrorHandler.handle_api_error(e, "ECI", region_id)
            ErrorHandler.handle_region_error(e, region_id, "ECI")
            return []

    def get_metrics(self, region: str, instance_id: str, days: int = 14):
        """è·å–ECIå®¹å™¨ç»„çš„ç›‘æ§æ•°æ® (BaseResourceAnalyzeræ¥å£)"""
        return self.get_eci_metrics(region, instance_id)

    def get_eci_metrics(self, region_id, container_group_id):
        """è·å–ECIå®¹å™¨ç»„çš„ç›‘æ§æ•°æ®"""
        client = AcsClient(self.access_key_id, self.access_key_secret, region_id)
        end_time = int(round(time.time() * 1000))
        start_time = end_time - 14 * 24 * 60 * 60 * 1000

        metrics = {
            "CpuTotal": "CPUæ€»é‡",
            "MemoryTotal": "å†…å­˜æ€»é‡",
            "NetworkRxRate": "ç½‘ç»œå…¥æµé‡",
            "NetworkTxRate": "ç½‘ç»œå‡ºæµé‡",
        }

        result = {}

        for metric_name, display_name in metrics.items():
            try:
                request = CommonRequest()
                request.set_domain(f"cms.{region_id}.aliyuncs.com")
                request.set_method("POST")
                request.set_version("2019-01-01")
                request.set_action_name("DescribeMetricData")
                request.add_query_param("RegionId", region_id)
                request.add_query_param("Namespace", "acs_eci_dashboard")
                request.add_query_param("MetricName", metric_name)
                request.add_query_param("StartTime", start_time)
                request.add_query_param("EndTime", end_time)
                request.add_query_param("Period", "86400")
                request.add_query_param(
                    "Dimensions", f'[{{"containerGroupId":"{container_group_id}"}}]'
                )

                response = client.do_action_with_exception(request)
                data = json.loads(response)

                if "Datapoints" in data and data["Datapoints"]:
                    if isinstance(data["Datapoints"], str):
                        dps = json.loads(data["Datapoints"])
                    else:
                        dps = data["Datapoints"]

                    if dps:
                        values = [float(dp.get("Average", 0)) for dp in dps if "Average" in dp]
                        if values:
                            result[display_name] = sum(values) / len(values)
                        else:
                            result[display_name] = 0
                    else:
                        result[display_name] = 0
                else:
                    result[display_name] = 0

                time.sleep(0.1)
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "ECI", region_id, container_group_id)
                result[display_name] = 0

        return result

    def save_eci_data(self, groups_data, monitoring_data):
        """ä¿å­˜ECIæ•°æ®åˆ°æ•°æ®åº“"""
        for group in groups_data:
            instance_dict = {
                "InstanceId": group.get("ContainerGroupId", ""),
                "InstanceName": group.get("ContainerGroupName", ""),
                "InstanceType": group.get("InstanceType", ""),
                "Region": group.get("RegionId", ""),
                "Status": group.get("Status", ""),
                "CreationTime": group.get("CreationTime", ""),
                "cpu": group.get("Cpu", 0),
                "memory": group.get("Memory", 0),
                "instance_type": group.get("InstanceType", ""),
            }
            self.db_manager.save_instance("eci", instance_dict)

        for group_id, metrics in monitoring_data.items():
            self.db_manager.save_metrics_batch("eci", group_id, metrics)

        self.logger.info(f"ECIæ•°æ®ä¿å­˜å®Œæˆ: {len(groups_data)}ä¸ªå®¹å™¨ç»„")

    def is_idle(self, instance, metrics, thresholds=None):
        """åˆ¤æ–­ECIå®¹å™¨ç»„æ˜¯å¦é—²ç½® (BaseResourceAnalyzeræ¥å£)"""
        is_idle = self.is_eci_idle(metrics)
        conditions = []
        if is_idle:
            conditions = [self.get_idle_reason(metrics)]
        return is_idle, conditions

    def get_optimization_suggestions(self, instance, metrics):
        """è·å–ä¼˜åŒ–å»ºè®® (BaseResourceAnalyzeræ¥å£)"""
        return self.get_optimization_suggestion(metrics, instance.get("InstanceType", ""))

    def is_eci_idle(self, metrics):
        """åˆ¤æ–­ECIå®¹å™¨ç»„æ˜¯å¦é—²ç½®"""
        cpu_total = metrics.get("CPUæ€»é‡", 0)
        memory_total = metrics.get("å†…å­˜æ€»é‡", 0)
        network_rx = metrics.get("ç½‘ç»œå…¥æµé‡", 0)
        network_tx = metrics.get("ç½‘ç»œå‡ºæµé‡", 0)

        # ECIé—²ç½®åˆ¤æ–­æ ‡å‡†
        if cpu_total < 0.1 and memory_total < 256:
            return True
        if network_rx < 1 and network_tx < 1:
            return True

        return False

    def get_idle_reason(self, metrics):
        """è·å–é—²ç½®åŸå› """
        reasons = []
        cpu_total = metrics.get("CPUæ€»é‡", 0)
        memory_total = metrics.get("å†…å­˜æ€»é‡", 0)
        network_rx = metrics.get("ç½‘ç»œå…¥æµé‡", 0)

        if cpu_total < 0.1:
            reasons.append(f"CPUæ€»é‡ {cpu_total:.2f}æ ¸ < 0.1æ ¸")
        if memory_total < 256:
            reasons.append(f"å†…å­˜æ€»é‡ {memory_total:.0f}MB < 256MB")
        if network_rx < 1:
            reasons.append(f"ç½‘ç»œæµé‡æä½")

        return ", ".join(reasons) if reasons else "æœªæ»¡è¶³é—²ç½®æ¡ä»¶"

    def get_optimization_suggestion(self, metrics, instance_type):
        """è·å–ä¼˜åŒ–å»ºè®®"""
        cpu_total = metrics.get("CPUæ€»é‡", 0)

        if cpu_total < 0.1:
            return "è€ƒè™‘åˆ é™¤å®¹å™¨ç»„ï¼ˆèµ„æºä½¿ç”¨æä½ï¼‰"
        else:
            return "æŒç»­ç›‘æ§ï¼Œè€ƒè™‘é™é…èµ„æºè§„æ ¼"

    def get_monthly_cost(self, container_group_id, cpu, memory, region):
        """è·å–æœˆåº¦æˆæœ¬ä¼°ç®—"""
        # ç®€åŒ–å®ç°ï¼ŒæŒ‰CPUå’Œå†…å­˜ä¼°ç®—
        return cpu * 100 + memory / 1024 * 50  # ç²—ç•¥ä¼°ç®—

    def analyze(self, regions=None, days=14):
        """åˆ†æèµ„æº (BaseResourceAnalyzeræ¥å£)"""
        # ECIAnalyzerçš„analyze_eci_resourcesé€»è¾‘æ¯”è¾ƒå¤æ‚
        return self.analyze_eci_resources()

    def generate_report(self, idle_instances):
        """ç”ŸæˆæŠ¥å‘Š (BaseResourceAnalyzeræ¥å£)"""
        self.generate_eci_report(idle_instances)

    def analyze_eci_resources(self):
        """åˆ†æECIèµ„æº"""
        self.init_database()
        self.logger.info("å¼€å§‹ECIèµ„æºåˆ†æ...")

        all_regions = self.get_all_regions()
        all_groups = []

        def get_region_groups(region_item):
            region_id = region_item
            try:
                groups = self.get_eci_container_groups(region_id)
                return {"success": True, "region": region_id, "groups": groups}
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "ECI", region_id)
                return {"success": False, "region": region_id, "groups": []}

        results = process_concurrently(
            all_regions, get_region_groups, max_workers=10, description="ECIå®¹å™¨ç»„é‡‡é›†"
        )

        for result in results:
            if result and result.get("success"):
                all_groups.extend(result["groups"])

        self.logger.info(f"æ€»å…±è·å–åˆ° {len(all_groups)} ä¸ªECIå®¹å™¨ç»„")

        def process_single_group(group_item):
            group = group_item
            group_id = group["ContainerGroupId"]
            region = group["RegionId"]

            try:
                metrics = self.get_eci_metrics(region, group_id)
                return {"success": True, "group_id": group_id, "metrics": metrics}
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "ECI", region, group_id)
                return {"success": False, "group_id": group_id, "metrics": {}, "error": str(e)}

        self.logger.info("å¹¶å‘è·å–ç›‘æ§æ•°æ®...")
        monitoring_results = process_concurrently(
            all_groups, process_single_group, max_workers=10, description="ECIç›‘æ§æ•°æ®é‡‡é›†"
        )

        all_monitoring_data = {}
        for result in monitoring_results:
            if result and result.get("success"):
                all_monitoring_data[result["group_id"]] = result["metrics"]

        self.save_eci_data(all_groups, all_monitoring_data)

        idle_groups = []
        for group in all_groups:
            group_id = group["ContainerGroupId"]
            metrics = all_monitoring_data.get(group_id, {})

            if self.is_eci_idle(metrics):
                idle_reason = self.get_idle_reason(metrics)
                optimization = self.get_optimization_suggestion(
                    metrics, group.get("InstanceType", "")
                )
                monthly_cost = self.get_monthly_cost(
                    group_id, group.get("Cpu", 0), group.get("Memory", 0), group["RegionId"]
                )

                idle_groups.append(
                    {
                        "å®¹å™¨ç»„ID": group_id,
                        "å®¹å™¨ç»„åç§°": group.get("ContainerGroupName", ""),
                        "å®ä¾‹ç±»å‹": group.get("InstanceType", ""),
                        "CPU(æ ¸)": group.get("Cpu", 0),
                        "å†…å­˜(GB)": group.get("Memory", 0) / 1024,
                        "åŒºåŸŸ": group["RegionId"],
                        "çŠ¶æ€": group.get("Status", ""),
                        "CPUæ€»é‡(æ ¸)": metrics.get("CPUæ€»é‡", 0),
                        "å†…å­˜æ€»é‡(MB)": metrics.get("å†…å­˜æ€»é‡", 0),
                        "ç½‘ç»œå…¥æµé‡(KB/s)": metrics.get("ç½‘ç»œå…¥æµé‡", 0),
                        "ç½‘ç»œå‡ºæµé‡(KB/s)": metrics.get("ç½‘ç»œå‡ºæµé‡", 0),
                        "é—²ç½®åŸå› ": idle_reason,
                        "ä¼˜åŒ–å»ºè®®": optimization,
                        "æœˆæˆæœ¬(Â¥)": monthly_cost,
                    }
                )

        self.logger.info(f"ECIåˆ†æå®Œæˆ: å‘ç° {len(idle_groups)} ä¸ªé—²ç½®å®¹å™¨ç»„")
        return idle_groups

    def generate_eci_report(self, idle_groups):
        """ç”ŸæˆECIæŠ¥å‘Š"""
        if not idle_groups:
            self.logger.info("æ²¡æœ‰å‘ç°é—²ç½®çš„ECIå®¹å™¨ç»„")
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        reports = ReportGenerator.generate_combined_report(
            resource_type="ECI",
            idle_instances=idle_groups,
            output_dir=".",
            tenant_name=self.tenant_name,
            timestamp=timestamp,
        )

        self.logger.info(f"ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {reports['excel']}")
        self.logger.info(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {reports['html']}")


def main():
    """ECIåˆ†æä¸»å‡½æ•°"""
    try:
        with open("config.json", "r") as f:
            config = json.load(f)
        access_key_id = config["access_key_id"]
        access_key_secret = config["access_key_secret"]
    except FileNotFoundError:
        import logging

        logging.error("é…ç½®æ–‡ä»¶ config.json ä¸å­˜åœ¨")
        return

    analyzer = ECIAnalyzer(access_key_id, access_key_secret)
    idle_groups = analyzer.analyze_eci_resources()
    analyzer.generate_eci_report(idle_groups)


if __name__ == "__main__":
    main()
