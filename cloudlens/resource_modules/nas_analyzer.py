#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NASèµ„æºåˆ†ææ¨¡å—
åˆ†æé˜¿é‡Œäº‘NASæ–‡ä»¶å­˜å‚¨çš„é—²ç½®æƒ…å†µï¼Œæä¾›ä¼˜åŒ–å»ºè®®
"""

import json
import sqlite3
import sys
import time
from datetime import datetime

from aliyunsdkcore.client import AcsClient
from aliyunsdkcore.request import CommonRequest

from cloudlens.core.analyzer_registry import AnalyzerRegistry
from cloudlens.core.base_analyzer import BaseResourceAnalyzer
from cloudlens.core.db_manager import DatabaseManager
from cloudlens.core.report_generator import ReportGenerator
from cloudlens.utils.concurrent_helper import process_concurrently
from cloudlens.utils.error_handler import ErrorHandler
from cloudlens.utils.logger import get_logger


@AnalyzerRegistry.register("nas", "NASæ–‡ä»¶å­˜å‚¨", "ğŸ“‚")
class NASAnalyzer(BaseResourceAnalyzer):
    """NASèµ„æºåˆ†æå™¨"""

    def __init__(self, access_key_id, access_key_secret, tenant_name=None):
        super().__init__(
            access_key_id=access_key_id,
            access_key_secret=access_key_secret,
            tenant_name=tenant_name or "default",
        )
        self.db_name = "nas_monitoring_data.db"
        self.logger = get_logger("nas_analyzer")
        self.db_manager = DatabaseManager(self.db_name)

    def get_resource_type(self) -> str:
        return "nas"

    def init_database(self):
        """åˆå§‹åŒ–NASæ•°æ®åº“"""
        extra_columns = {"storage_type": "TEXT", "protocol_type": "TEXT", "capacity": "REAL"}
        self.db_manager.create_resource_table("nas", extra_columns)
        self.db_manager.create_monitoring_table("nas")
        self.logger.info("NASæ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    def get_all_regions(self):
        """è·å–æ‰€æœ‰å¯ç”¨åŒºåŸŸ"""
        client = AcsClient(self.access_key_id, self.access_key_secret, "cn-hangzhou")
        request = CommonRequest()
        request.set_domain("ecs.cn-hangzhou.aliyuncs.com")
        request.set_method("POST")
        request.set_version("2014-05-26")
        request.set_action_name("DescribeRegions")

        response = client.do_action_with_exception(request)
        data = json.loads(response)

        regions = []
        for region in data["Regions"]["Region"]:
            regions.append(region["RegionId"])

        return regions

    def get_instances(self, region: str):
        """è·å–æŒ‡å®šåŒºåŸŸçš„NASæ–‡ä»¶ç³»ç»Ÿ (BaseResourceAnalyzeræ¥å£)"""
        return self.get_nas_file_systems(region)

    def get_nas_file_systems(self, region_id):
        """è·å–æŒ‡å®šåŒºåŸŸçš„NASæ–‡ä»¶ç³»ç»Ÿ"""
        try:
            client = AcsClient(self.access_key_id, self.access_key_secret, region_id)
            request = CommonRequest()
            request.set_domain(f"nas.{region_id}.aliyuncs.com")
            request.set_method("POST")
            request.set_version("2017-06-26")
            request.set_action_name("DescribeFileSystems")
            request.add_query_param("PageSize", 100)
            request.add_query_param("PageNumber", 1)

            all_file_systems = []
            page_number = 1

            while True:
                request.add_query_param("PageNumber", page_number)
                response = client.do_action_with_exception(request)
                data = json.loads(response)

                if "FileSystems" in data and "FileSystem" in data["FileSystems"]:
                    file_systems = data["FileSystems"]["FileSystem"]
                    if not isinstance(file_systems, list):
                        file_systems = [file_systems]

                    if len(file_systems) == 0:
                        break

                    for fs in file_systems:
                        all_file_systems.append(
                            {
                                "FileSystemId": fs.get("FileSystemId", ""),
                                "Description": fs.get("Description", ""),
                                "StorageType": fs.get("StorageType", ""),
                                "ProtocolType": fs.get("ProtocolType", ""),
                                "Capacity": fs.get("Capacity", 0),
                                "MeteredSize": fs.get("MeteredSize", 0),
                                "RegionId": fs.get("RegionId", region_id),
                                "ZoneId": fs.get("ZoneId", ""),
                                "Status": fs.get("Status", ""),
                                "CreateTime": fs.get("CreateTime", ""),
                            }
                        )

                    page_number += 1

                    if len(file_systems) < 100:
                        break
                else:
                    break

            return all_file_systems
        except Exception as e:
            error = ErrorHandler.handle_api_error(e, "NAS", region_id)
            ErrorHandler.handle_region_error(e, region_id, "NAS")
            return []

    def get_metrics(self, region: str, instance_id: str, days: int = 14):
        """è·å–NASæ–‡ä»¶ç³»ç»Ÿçš„ç›‘æ§æ•°æ® (BaseResourceAnalyzeræ¥å£)"""
        return self.get_nas_metrics(region, instance_id)

    def get_nas_metrics(self, region_id, file_system_id):
        """è·å–NASæ–‡ä»¶ç³»ç»Ÿçš„ç›‘æ§æ•°æ®"""
        client = AcsClient(self.access_key_id, self.access_key_secret, region_id)
        end_time = int(round(time.time() * 1000))
        start_time = end_time - 14 * 24 * 60 * 60 * 1000  # 14å¤©å‰

        metrics = {
            "DiskSize": "å­˜å‚¨å®¹é‡",
            "DiskUsed": "å·²ç”¨å®¹é‡",
            "DiskUtilization": "å®¹é‡ä½¿ç”¨ç‡",
            "FilesystemInodesFree": "å¯ç”¨inodeæ•°",
            "FilesystemInodesTotal": "æ€»inodeæ•°",
            "FilesystemInodesUtilization": "inodeä½¿ç”¨ç‡",
        }

        result = {}

        for metric_name, display_name in metrics.items():
            try:
                request = CommonRequest()
                request.set_domain(f"cms.{region_id}.aliyuncs.com")
                request.set_method("POST")
                request.set_version("2019-01-01")
                request.set_action_name("DescribeMetricData")
                request.add_query_param("RegionId", region_id)
                request.add_query_param("Namespace", "acs_nas")
                request.add_query_param("MetricName", metric_name)
                request.add_query_param("StartTime", start_time)
                request.add_query_param("EndTime", end_time)
                request.add_query_param("Period", "86400")
                request.add_query_param("Dimensions", f'[{{"filesystemId":"{file_system_id}"}}]')

                response = client.do_action_with_exception(request)
                data = json.loads(response)

                if "Datapoints" in data and data["Datapoints"]:
                    if isinstance(data["Datapoints"], str):
                        dps = json.loads(data["Datapoints"])
                    else:
                        dps = data["Datapoints"]

                    if dps:
                        values = [float(dp.get("Average", 0)) for dp in dps if "Average" in dp]
                        if values:
                            result[display_name] = sum(values) / len(values)
                        else:
                            result[display_name] = 0
                    else:
                        result[display_name] = 0
                else:
                    result[display_name] = 0

                time.sleep(0.1)
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "NAS", region_id, file_system_id)
                result[display_name] = 0

        return result

    def save_nas_data(self, file_systems_data, monitoring_data):
        """ä¿å­˜NASæ•°æ®åˆ°æ•°æ®åº“"""
        for fs in file_systems_data:
            instance_dict = {
                "InstanceId": fs.get("FileSystemId", ""),
                "InstanceName": fs.get("Description", ""),
                "InstanceType": fs.get("StorageType", ""),
                "Region": fs.get("RegionId", ""),
                "Status": fs.get("Status", ""),
                "CreationTime": fs.get("CreateTime", ""),
                "storage_type": fs.get("StorageType", ""),
                "protocol_type": fs.get("ProtocolType", ""),
                "capacity": fs.get("Capacity", 0),
            }
            self.db_manager.save_instance("nas", instance_dict)

        for fs_id, metrics in monitoring_data.items():
            self.db_manager.save_metrics_batch("nas", fs_id, metrics)

        self.logger.info(f"NASæ•°æ®ä¿å­˜å®Œæˆ: {len(file_systems_data)}ä¸ªæ–‡ä»¶ç³»ç»Ÿ")

    def is_idle(self, instance, metrics, thresholds=None):
        """åˆ¤æ–­NASæ–‡ä»¶ç³»ç»Ÿæ˜¯å¦é—²ç½® (BaseResourceAnalyzeræ¥å£)"""
        is_idle = self.is_nas_idle(metrics)
        conditions = []
        if is_idle:
            conditions = [self.get_idle_reason(metrics)]
        return is_idle, conditions

    def get_optimization_suggestions(self, instance, metrics):
        """è·å–ä¼˜åŒ–å»ºè®® (BaseResourceAnalyzeræ¥å£)"""
        return self.get_optimization_suggestion(metrics, instance.get("StorageType", ""))

    def is_nas_idle(self, metrics):
        """åˆ¤æ–­NASæ–‡ä»¶ç³»ç»Ÿæ˜¯å¦é—²ç½®"""
        capacity_util = metrics.get("å®¹é‡ä½¿ç”¨ç‡", 0)
        inode_util = metrics.get("inodeä½¿ç”¨ç‡", 0)

        # NASé—²ç½®åˆ¤æ–­æ ‡å‡†ï¼ˆæˆ–å…³ç³»ï¼‰
        if capacity_util < 10:
            return True
        if inode_util < 10:
            return True

        return False

    def get_idle_reason(self, metrics):
        """è·å–é—²ç½®åŸå› """
        reasons = []
        capacity_util = metrics.get("å®¹é‡ä½¿ç”¨ç‡", 0)
        inode_util = metrics.get("inodeä½¿ç”¨ç‡", 0)

        if capacity_util < 10:
            reasons.append(f"å®¹é‡ä½¿ç”¨ç‡ {capacity_util:.2f}% < 10%")
        if inode_util < 10:
            reasons.append(f"inodeä½¿ç”¨ç‡ {inode_util:.2f}% < 10%")

        return ", ".join(reasons) if reasons else "æœªæ»¡è¶³é—²ç½®æ¡ä»¶"

    def get_optimization_suggestion(self, metrics, storage_type):
        """è·å–ä¼˜åŒ–å»ºè®®"""
        capacity_util = metrics.get("å®¹é‡ä½¿ç”¨ç‡", 0)

        if capacity_util < 5:
            return "è€ƒè™‘åˆ é™¤æ–‡ä»¶ç³»ç»Ÿï¼ˆä½¿ç”¨ç‡æä½ï¼‰"
        elif capacity_util < 20:
            return "è€ƒè™‘é™é…å­˜å‚¨ç±»å‹æˆ–å®¹é‡"
        else:
            return "æŒç»­ç›‘æ§ï¼Œè€ƒè™‘åˆå¹¶å°æ–‡ä»¶ç³»ç»Ÿ"

    def get_monthly_cost(self, file_system_id, storage_type, region):
        """è·å–æœˆåº¦æˆæœ¬ä¼°ç®—"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ä»Billing APIè·å–
        return 200.0  # é»˜è®¤200å…ƒ/æœˆ

    def analyze(self, regions=None, days=14):
        """åˆ†æèµ„æº (BaseResourceAnalyzeræ¥å£)"""
        # NASAnalyzerçš„analyze_nas_resourcesé€»è¾‘æ¯”è¾ƒå¤æ‚
        return self.analyze_nas_resources()

    def generate_report(self, idle_instances):
        """ç”ŸæˆæŠ¥å‘Š (BaseResourceAnalyzeræ¥å£)"""
        self.generate_nas_report(idle_instances)

    def analyze_nas_resources(self):
        """åˆ†æNASèµ„æº"""
        self.init_database()
        self.logger.info("å¼€å§‹NASèµ„æºåˆ†æ...")

        all_regions = self.get_all_regions()
        self.logger.info(f"è·å–åˆ° {len(all_regions)} ä¸ªåŒºåŸŸ")

        all_file_systems = []

        def get_region_file_systems(region_item):
            region_id = region_item
            try:
                file_systems = self.get_nas_file_systems(region_id)
                return {"success": True, "region": region_id, "file_systems": file_systems}
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "NAS", region_id)
                return {"success": False, "region": region_id, "file_systems": []}

        results = process_concurrently(
            all_regions, get_region_file_systems, max_workers=10, description="NASæ–‡ä»¶ç³»ç»Ÿé‡‡é›†"
        )

        for result in results:
            if result and result.get("success"):
                all_file_systems.extend(result["file_systems"])

        self.logger.info(f"æ€»å…±è·å–åˆ° {len(all_file_systems)} ä¸ªNASæ–‡ä»¶ç³»ç»Ÿ")

        def process_single_file_system(fs_item):
            fs = fs_item
            file_system_id = fs["FileSystemId"]
            region = fs["RegionId"]

            try:
                metrics = self.get_nas_metrics(region, file_system_id)
                return {"success": True, "file_system_id": file_system_id, "metrics": metrics}
            except Exception as e:
                error = ErrorHandler.handle_api_error(e, "NAS", region, file_system_id)
                return {
                    "success": False,
                    "file_system_id": file_system_id,
                    "metrics": {},
                    "error": str(e),
                }

        self.logger.info("å¹¶å‘è·å–ç›‘æ§æ•°æ®ï¼ˆæœ€å¤š10ä¸ªå¹¶å‘çº¿ç¨‹ï¼‰...")

        monitoring_results = process_concurrently(
            all_file_systems,
            process_single_file_system,
            max_workers=10,
            description="NASç›‘æ§æ•°æ®é‡‡é›†",
        )

        all_monitoring_data = {}
        success_count = 0
        fail_count = 0

        for result in monitoring_results:
            if result and result.get("success"):
                all_monitoring_data[result["file_system_id"]] = result["metrics"]
                success_count += 1
            else:
                if result:
                    file_system_id = result.get("file_system_id", "unknown")
                    all_monitoring_data[file_system_id] = {}
                    fail_count += 1

        self.logger.info(f"ç›‘æ§æ•°æ®è·å–å®Œæˆ: æˆåŠŸ {success_count} ä¸ª, å¤±è´¥ {fail_count} ä¸ª")

        self.save_nas_data(all_file_systems, all_monitoring_data)

        idle_file_systems = []

        for fs in all_file_systems:
            file_system_id = fs["FileSystemId"]
            metrics = all_monitoring_data.get(file_system_id, {})

            if self.is_nas_idle(metrics):
                idle_reason = self.get_idle_reason(metrics)
                optimization = self.get_optimization_suggestion(metrics, fs.get("StorageType", ""))
                monthly_cost = self.get_monthly_cost(
                    file_system_id, fs.get("StorageType", ""), fs["RegionId"]
                )

                idle_file_systems.append(
                    {
                        "æ–‡ä»¶ç³»ç»ŸID": file_system_id,
                        "æ–‡ä»¶ç³»ç»Ÿåç§°": fs.get("Description", ""),
                        "å­˜å‚¨ç±»å‹": fs.get("StorageType", ""),
                        "åè®®ç±»å‹": fs.get("ProtocolType", ""),
                        "åŒºåŸŸ": fs["RegionId"],
                        "çŠ¶æ€": fs.get("Status", ""),
                        "å®¹é‡ä½¿ç”¨ç‡(%)": metrics.get("å®¹é‡ä½¿ç”¨ç‡", 0),
                        "inodeä½¿ç”¨ç‡(%)": metrics.get("inodeä½¿ç”¨ç‡", 0),
                        "å·²ç”¨å®¹é‡(GB)": (
                            metrics.get("å·²ç”¨å®¹é‡", 0) / 1024 / 1024 / 1024
                            if metrics.get("å·²ç”¨å®¹é‡", 0) > 0
                            else 0
                        ),
                        "é—²ç½®åŸå› ": idle_reason,
                        "ä¼˜åŒ–å»ºè®®": optimization,
                        "æœˆæˆæœ¬(Â¥)": monthly_cost,
                    }
                )

        self.logger.info(f"NASåˆ†æå®Œæˆ: å‘ç° {len(idle_file_systems)} ä¸ªé—²ç½®æ–‡ä»¶ç³»ç»Ÿ")
        return idle_file_systems

    def generate_nas_report(self, idle_file_systems):
        """ç”ŸæˆNASæŠ¥å‘Š"""
        if not idle_file_systems:
            self.logger.info("æ²¡æœ‰å‘ç°é—²ç½®çš„NASæ–‡ä»¶ç³»ç»Ÿ")
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        reports = ReportGenerator.generate_combined_report(
            resource_type="NAS",
            idle_instances=idle_file_systems,
            output_dir=".",
            tenant_name=self.tenant_name,
            timestamp=timestamp,
        )

        self.logger.info(f"ExcelæŠ¥å‘Šå·²ç”Ÿæˆ: {reports['excel']}")
        self.logger.info(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {reports['html']}")

        total_cost = sum(fs.get("æœˆæˆæœ¬(Â¥)", 0) for fs in idle_file_systems)
        self.logger.info(
            f"NASé—²ç½®æ–‡ä»¶ç³»ç»Ÿç»Ÿè®¡: æ€»æ•°é‡={len(idle_file_systems)}ä¸ª, æ€»æœˆæˆæœ¬={total_cost:,.2f}å…ƒ, é¢„è®¡å¹´èŠ‚çœ={total_cost * 12:,.2f}å…ƒ"
        )


def main():
    """NASåˆ†æä¸»å‡½æ•°"""
    try:
        with open("config.json", "r") as f:
            config = json.load(f)
        access_key_id = config["access_key_id"]
        access_key_secret = config["access_key_secret"]
    except FileNotFoundError:
        import logging

        logging.error("é…ç½®æ–‡ä»¶ config.json ä¸å­˜åœ¨")
        return

    analyzer = NASAnalyzer(access_key_id, access_key_secret)
    idle_file_systems = analyzer.analyze_nas_resources()
    analyzer.generate_nas_report(idle_file_systems)


if __name__ == "__main__":
    main()
